{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 619
    },
    "colab_type": "code",
    "id": "J9cGEmt9Rx2X",
    "outputId": "3a18c1e3-56e4-4dab-bea9-2f657c1b925b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers==2.10.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/12/b5/ac41e3e95205ebf53439e4dd087c58e9fd371fd8e3724f2b9b4cdb8282e5/transformers-2.10.0-py3-none-any.whl (660kB)\n",
      "\u001b[K     |████████████████████████████████| 665kB 2.5MB/s \n",
      "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers==2.10.0) (2.23.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers==2.10.0) (3.0.12)\n",
      "Collecting tokenizers==0.7.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/e5/a26eb4716523808bb0a799fcfdceb6ebf77a18169d9591b2f46a9adb87d9/tokenizers-0.7.0-cp36-cp36m-manylinux1_x86_64.whl (3.8MB)\n",
      "\u001b[K     |████████████████████████████████| 3.8MB 6.3MB/s \n",
      "\u001b[?25hCollecting sentencepiece\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
      "\u001b[K     |████████████████████████████████| 1.1MB 29.9MB/s \n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers==2.10.0) (4.41.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers==2.10.0) (1.18.5)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers==2.10.0) (2019.12.20)\n",
      "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers==2.10.0) (0.7)\n",
      "Collecting sacremoses\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
      "\u001b[K     |████████████████████████████████| 890kB 20.3MB/s \n",
      "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.10.0) (2020.6.20)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.10.0) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.10.0) (1.24.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.10.0) (2.10)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.10.0) (1.12.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.10.0) (7.1.2)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.10.0) (0.16.0)\n",
      "Building wheels for collected packages: sacremoses\n",
      "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=3c2cc90d2fd4bb5a62bdd69fc4380eb5d2e8d4b8b72bfe673624e3edec3ba2e8\n",
      "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
      "Successfully built sacremoses\n",
      "Installing collected packages: tokenizers, sentencepiece, sacremoses, transformers\n",
      "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.7.0 transformers-2.10.0\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers==2.10.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "z8fvpJPOOSzg",
    "outputId": "d15ea35a-a698-4085-b1e3-8d5a716ebcdb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E_hfei11VX05"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('./drive/My Drive/Reviews.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 285
    },
    "colab_type": "code",
    "id": "fuap67cMS5dm",
    "outputId": "39595c3a-9c8b-45ba-cdac-196cd8a246f7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>delmartian</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>dll pa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1346976000</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>ABXLMWJIXXAIN</td>\n",
       "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1219017600</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>B000UA0QIQ</td>\n",
       "      <td>A395BORC6FGVXV</td>\n",
       "      <td>Karl</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1307923200</td>\n",
       "      <td>Cough Medicine</td>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>A1UQRSCLF8GW1T</td>\n",
       "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1350777600</td>\n",
       "      <td>Great taffy</td>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  ...                                               Text\n",
       "0   1  ...  I have bought several of the Vitality canned d...\n",
       "1   2  ...  Product arrived labeled as Jumbo Salted Peanut...\n",
       "2   3  ...  This is a confection that has been around a fe...\n",
       "3   4  ...  If you are looking for the secret ingredient i...\n",
       "4   5  ...  Great taffy at a great price.  There was a wid...\n",
       "\n",
       "[5 rows x 10 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 198
    },
    "colab_type": "code",
    "id": "bJ0lqqM4UaLr",
    "outputId": "295b97e9-a8bc-4760-95a0-40cea032bb81"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>378653</th>\n",
       "      <td>Got me on the tea bandwagon</td>\n",
       "      <td>When in Boulder this summer I took a tour of t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31688</th>\n",
       "      <td>It's the Cats' Meow</td>\n",
       "      <td>This is one of the best products that we have ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546841</th>\n",
       "      <td>good dog food</td>\n",
       "      <td>switched over to this because of the new puppy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165476</th>\n",
       "      <td>great price for a great product</td>\n",
       "      <td>I love Eight O'clock coffee, and I love grindi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>528832</th>\n",
       "      <td>My favorite</td>\n",
       "      <td>I'll be honest only the home made house french...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Summary                                               Text\n",
       "378653      Got me on the tea bandwagon  When in Boulder this summer I took a tour of t...\n",
       "31688               It's the Cats' Meow  This is one of the best products that we have ...\n",
       "546841                    good dog food  switched over to this because of the new puppy...\n",
       "165476  great price for a great product  I love Eight O'clock coffee, and I love grindi...\n",
       "528832                      My favorite  I'll be honest only the home made house french..."
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df.Score == 5].sample(5)[['Summary', 'Text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 198
    },
    "colab_type": "code",
    "id": "IVqcm1YIWvYc",
    "outputId": "300ebdce-289c-4e61-f75d-1c30f8b92c88"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>136831</th>\n",
       "      <td>kind of gross</td>\n",
       "      <td>I love green tea and maybe I'm just not used t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428196</th>\n",
       "      <td>These bubbles scare the kitties - indoor and o...</td>\n",
       "      <td>I got a bottle of these bubbles for my brother...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499382</th>\n",
       "      <td>Kio is dying..</td>\n",
       "      <td>After reading the reviews, I searched the web ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70311</th>\n",
       "      <td>Garbage! False Description!</td>\n",
       "      <td>All you can taste is artificial sweetener. It ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38279</th>\n",
       "      <td>Duped</td>\n",
       "      <td>Because they showed six barbells for the price...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Summary                                               Text\n",
       "136831                                      kind of gross  I love green tea and maybe I'm just not used t...\n",
       "428196  These bubbles scare the kitties - indoor and o...  I got a bottle of these bubbles for my brother...\n",
       "499382                                     Kio is dying..  After reading the reviews, I searched the web ...\n",
       "70311                         Garbage! False Description!  All you can taste is artificial sweetener. It ...\n",
       "38279                                               Duped  Because they showed six barbells for the price..."
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df.Score == 1].sample(5)[['Summary', 'Text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "91Mm0V0KTLBr",
    "outputId": "1ef2bca0-aedd-4005-df4a-9dc7ca479a43"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 1 0 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "sentences = df.Text.values\n",
    "labels = df.Score.values - 1\n",
    "\n",
    "#sentences = df.Summary.values\n",
    "\n",
    "#sentences = sentences[:1000]\n",
    "#labels = (labels[:1000]).astype(int)\n",
    "\n",
    "idx = np.where(labels==2)\n",
    "labels = np.delete(labels, idx)\n",
    "sentences = np.delete(sentences, idx)\n",
    "#labels = np.array([l for l in labels if l in {0,1,3,4}])\n",
    "labels = (labels>2).astype(int)\n",
    "print(labels[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 117,
     "referenced_widgets": [
      "cd71e1f5340c4c06bf25a238b93a3304",
      "db78ceb0e26d467c8f0144698b8344c3",
      "7485244de9e341f28b0cc7e00c32ac7e",
      "91a552bae06e432bb7b48c330eb258f7",
      "d70562775d9f444b870d52f744a2ddac",
      "e8e95befa64f456e8c4cb97a3cf29305",
      "ad89dadf9ef048479a313f640ae62b52",
      "703a44b858ca4ad2a09590d09f1c0415",
      "c076bc5728994168b6263d91768d8d6c",
      "cc17fdd219cd43049944a6d8c72fb2a7",
      "0abff727c8474082a391526fe3e5398a",
      "d264cf5ee28d4dbcb8eb0d8a614e007e",
      "4eb582dc791b4324ba919c932409a3ce",
      "5fafe301182a4e53863f88d2d8c17965",
      "ac463a6bbe7146cb9237db3264a3eebe",
      "0d794f34fd764c49ae6c191571f16170"
     ]
    },
    "colab_type": "code",
    "id": "rMP_kv7UVRY3",
    "outputId": "cc95c1ce-5b90-4a4c-bd3e-6282afcc4196"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd71e1f5340c4c06bf25a238b93a3304",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=898823.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c076bc5728994168b6263d91768d8d6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=456318.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import RobertaTokenizer\n",
    "max_len = 0\n",
    "\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base', do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 328
    },
    "colab_type": "code",
    "id": "ve8LZkNsUEjX",
    "outputId": "76168882-38c9-4723-a8b1-1d3ba4592954"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phase score: 1\n",
      "Original:  This is a confection that has been around a few centuries.  It is a light, pillowy citrus gelatin with nuts - in this case Filberts. And it is cut into tiny squares and then liberally coated with powdered sugar.  And it is a tiny mouthful of heaven.  Not too chewy, and very flavorful.  I highly recommend this yummy treat.  If you are familiar with the story of C.S. Lewis' \"The Lion, The Witch, and The Wardrobe\" - this is the treat that seduces Edmund into selling out his Brother and Sisters to the Witch.\n",
      "Token IDs: tensor([    0,    42,    16,    10,  7856, 20970,    14,    34,    57,   198,\n",
      "           10,   367, 11505,     4,  1437,    24,    16,    10,  1109,     6,\n",
      "        26410,   219, 28460, 44496,    19, 15092,   111,    11,    42,   403,\n",
      "        14242,  1943,  1872,     4,     8,    24,    16,   847,    88,  5262,\n",
      "        32657,     8,   172, 25232,  2368, 31444,    19, 39143,  4696,     4,\n",
      "         1437,     8,    24,    16,    10,  5262,  6085,  2650,     9, 18478,\n",
      "            4,  1437,    45,   350,  5851, 13434,     6,     8,   182, 41202,\n",
      "            4,  1437,   939,  2200,  5940,    42,  1423, 22383,  3951,     4,\n",
      "         1437,   114,    47,    32,  2950,    19,     5,   527,     9,   740,\n",
      "            4,    29,     4,  2084,   605,   354,   108,    22,   627, 15587,\n",
      "            6,     5, 22048,     6,     8,     5, 18704,   113,   111,    42,\n",
      "           16,     5,  3951,    14, 10195, 41235,  4803, 34140,    88,  2183,\n",
      "           66,    39,  2138,     8,  7502,     7,     5,     2])\n",
      "phase score: tensor(1)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "input_ids = []\n",
    "attention_masks = []\n",
    "\n",
    "# For every sentence...\n",
    "for sent in sentences:\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        sent, \n",
    "                        add_special_tokens = True, \n",
    "                        max_length = 128,           \n",
    "                        pad_to_max_length = True,\n",
    "                        return_attention_mask = True,  \n",
    "                        return_tensors = 'pt'   \n",
    "                   )  \n",
    "    input_ids.append(encoded_dict['input_ids'])\n",
    "    \n",
    "    attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "input_ids = torch.cat(input_ids, dim=0)\n",
    "attention_masks = torch.cat(attention_masks, dim=0)\n",
    "print('phase score:', labels[2])\n",
    "labels = torch.tensor(labels)\n",
    "\n",
    "print('Original: ', sentences[2])\n",
    "print('Token IDs:', input_ids[2])\n",
    "print('phase score:', labels[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "k94Ttom4V5C_",
    "outputId": "4fcd3ff7-8c19-4d2c-d085-bda3463cfe64"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "473,232 training samples\n",
      "52,582 validation samples\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset, random_split\n",
    "\n",
    "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "print('{:>5,} training samples'.format(train_size))\n",
    "print('{:>5,} validation samples'.format(val_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XHmhJQCpbM38"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "batch_size = 32\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "            train_dataset,  \n",
    "            sampler = RandomSampler(train_dataset), \n",
    "            batch_size = batch_size \n",
    "        )\n",
    "\n",
    "validation_dataloader = DataLoader(\n",
    "            val_dataset, \n",
    "            sampler = SequentialSampler(val_dataset), \n",
    "            batch_size = batch_size \n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "ed4b291d5a414a6ab92333b57e666c2c",
      "566aed6c7c9747eebf3f20a438c6d60d",
      "cc4cdf98053a4f06a9ea2056f35a3d29",
      "24352e494a794a17a0d3a40c65a9f348",
      "3223227416434d278cdeaf0b201f0546",
      "4b126a7b755c418984a3890fbd0726b0",
      "50e27af94a474c8c94ac6ff0edfe7afc",
      "c6aed81e509843fa9ee6e9bb8e6220c7",
      "15698980e87846609ab193ebfe1ef349",
      "4c22c969cf054857b1f743571148e7bc",
      "cffec5b9ee254bb19846ecd80ff4cb22",
      "07b24e917df6498586fd161c68f77072",
      "6cf378a35fa54fcfbabc73d95b39cfe0",
      "8a1712076b494f849fff037a6a2e67e6",
      "bb1e545aff1d4046b48c19d22205f952",
      "4e1990521961423ab3065a568556d343"
     ]
    },
    "colab_type": "code",
    "id": "OQ4BqlvSbU9e",
    "outputId": "3ee4ea3d-0816-430a-a2b4-3a053c747485"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed4b291d5a414a6ab92333b57e666c2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=481.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15698980e87846609ab193ebfe1ef349",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=501200538.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RobertaForSequenceClassification(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (classifier): RobertaClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import RobertaForSequenceClassification, AdamW, BertConfig\n",
    "\n",
    "model = RobertaForSequenceClassification.from_pretrained(\n",
    "    \"roberta-base\", \n",
    "    num_labels = 2,  \n",
    "    output_attentions = False, \n",
    "    output_hidden_states = False, \n",
    ")\n",
    "\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "41kQhkgIbcr3"
   },
   "outputs": [],
   "source": [
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = 4e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
    "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
    "                )\n",
    "\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "epochs = 4\n",
    "\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
    "                                            num_training_steps = total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0cLPmViCd95v"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b6vQl50weDLL"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "\n",
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    \n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "anRVJWwJQK73"
   },
   "outputs": [],
   "source": [
    "#torch.cuda.empty_cache()\n",
    "#PATH = '/content/drive/My Drive/data'\n",
    "#torch.save(model.state_dict(),PATH + '//'+ str(50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "jTf6BDUneD8j",
    "outputId": "4ee46a5d-906c-4ba7-8fd0-000b0e795a40"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 4 ========\n",
      "Training...\n",
      "  Batch    40  of  14,789.    Elapsed: 0:00:16.\n",
      "  Batch    80  of  14,789.    Elapsed: 0:00:31.\n",
      "  Batch   120  of  14,789.    Elapsed: 0:00:46.\n",
      "  Batch   160  of  14,789.    Elapsed: 0:01:01.\n",
      "  Batch   200  of  14,789.    Elapsed: 0:01:16.\n",
      "  Batch   240  of  14,789.    Elapsed: 0:01:31.\n",
      "  Batch   280  of  14,789.    Elapsed: 0:01:46.\n",
      "  Batch   320  of  14,789.    Elapsed: 0:02:01.\n",
      "  Batch   360  of  14,789.    Elapsed: 0:02:16.\n",
      "  Batch   400  of  14,789.    Elapsed: 0:02:31.\n",
      "  Batch   440  of  14,789.    Elapsed: 0:02:47.\n",
      "  Batch   480  of  14,789.    Elapsed: 0:03:02.\n",
      "  Batch   520  of  14,789.    Elapsed: 0:03:17.\n",
      "  Batch   560  of  14,789.    Elapsed: 0:03:32.\n",
      "  Batch   600  of  14,789.    Elapsed: 0:03:47.\n",
      "  Batch   640  of  14,789.    Elapsed: 0:04:02.\n",
      "  Batch   680  of  14,789.    Elapsed: 0:04:17.\n",
      "  Batch   720  of  14,789.    Elapsed: 0:04:32.\n",
      "  Batch   760  of  14,789.    Elapsed: 0:04:47.\n",
      "  Batch   800  of  14,789.    Elapsed: 0:05:02.\n",
      "  Batch   840  of  14,789.    Elapsed: 0:05:17.\n",
      "  Batch   880  of  14,789.    Elapsed: 0:05:33.\n",
      "  Batch   920  of  14,789.    Elapsed: 0:05:48.\n",
      "  Batch   960  of  14,789.    Elapsed: 0:06:03.\n",
      "  Batch 1,000  of  14,789.    Elapsed: 0:06:18.\n",
      "  Batch 1,040  of  14,789.    Elapsed: 0:06:33.\n",
      "  Batch 1,080  of  14,789.    Elapsed: 0:06:48.\n",
      "  Batch 1,120  of  14,789.    Elapsed: 0:07:03.\n",
      "  Batch 1,160  of  14,789.    Elapsed: 0:07:18.\n",
      "  Batch 1,200  of  14,789.    Elapsed: 0:07:33.\n",
      "  Batch 1,240  of  14,789.    Elapsed: 0:07:48.\n",
      "  Batch 1,280  of  14,789.    Elapsed: 0:08:03.\n",
      "  Batch 1,320  of  14,789.    Elapsed: 0:08:18.\n",
      "  Batch 1,360  of  14,789.    Elapsed: 0:08:34.\n",
      "  Batch 1,400  of  14,789.    Elapsed: 0:08:49.\n",
      "  Batch 1,440  of  14,789.    Elapsed: 0:09:04.\n",
      "  Batch 1,480  of  14,789.    Elapsed: 0:09:19.\n",
      "  Batch 1,520  of  14,789.    Elapsed: 0:09:34.\n",
      "  Batch 1,560  of  14,789.    Elapsed: 0:09:49.\n",
      "  Batch 1,600  of  14,789.    Elapsed: 0:10:04.\n",
      "  Batch 1,640  of  14,789.    Elapsed: 0:10:19.\n",
      "  Batch 1,680  of  14,789.    Elapsed: 0:10:34.\n",
      "  Batch 1,720  of  14,789.    Elapsed: 0:10:49.\n",
      "  Batch 1,760  of  14,789.    Elapsed: 0:11:04.\n",
      "  Batch 1,800  of  14,789.    Elapsed: 0:11:20.\n",
      "  Batch 1,840  of  14,789.    Elapsed: 0:11:35.\n",
      "  Batch 1,880  of  14,789.    Elapsed: 0:11:50.\n",
      "  Batch 1,920  of  14,789.    Elapsed: 0:12:05.\n",
      "  Batch 1,960  of  14,789.    Elapsed: 0:12:20.\n",
      "  Batch 2,000  of  14,789.    Elapsed: 0:12:35.\n",
      "  Batch 2,040  of  14,789.    Elapsed: 0:12:52.\n",
      "  Batch 2,080  of  14,789.    Elapsed: 0:13:07.\n",
      "  Batch 2,120  of  14,789.    Elapsed: 0:13:22.\n",
      "  Batch 2,160  of  14,789.    Elapsed: 0:13:37.\n",
      "  Batch 2,200  of  14,789.    Elapsed: 0:13:52.\n",
      "  Batch 2,240  of  14,789.    Elapsed: 0:14:07.\n",
      "  Batch 2,280  of  14,789.    Elapsed: 0:14:22.\n",
      "  Batch 2,320  of  14,789.    Elapsed: 0:14:37.\n",
      "  Batch 2,360  of  14,789.    Elapsed: 0:14:52.\n",
      "  Batch 2,400  of  14,789.    Elapsed: 0:15:07.\n",
      "  Batch 2,440  of  14,789.    Elapsed: 0:15:23.\n",
      "  Batch 2,480  of  14,789.    Elapsed: 0:15:38.\n",
      "  Batch 2,520  of  14,789.    Elapsed: 0:15:53.\n",
      "  Batch 2,560  of  14,789.    Elapsed: 0:16:08.\n",
      "  Batch 2,600  of  14,789.    Elapsed: 0:16:23.\n",
      "  Batch 2,640  of  14,789.    Elapsed: 0:16:38.\n",
      "  Batch 2,680  of  14,789.    Elapsed: 0:16:53.\n",
      "  Batch 2,720  of  14,789.    Elapsed: 0:17:08.\n",
      "  Batch 2,760  of  14,789.    Elapsed: 0:17:23.\n",
      "  Batch 2,800  of  14,789.    Elapsed: 0:17:38.\n",
      "  Batch 2,840  of  14,789.    Elapsed: 0:17:54.\n",
      "  Batch 2,880  of  14,789.    Elapsed: 0:18:09.\n",
      "  Batch 2,920  of  14,789.    Elapsed: 0:18:24.\n",
      "  Batch 2,960  of  14,789.    Elapsed: 0:18:39.\n",
      "  Batch 3,000  of  14,789.    Elapsed: 0:18:54.\n",
      "  Batch 3,040  of  14,789.    Elapsed: 0:19:09.\n",
      "  Batch 3,080  of  14,789.    Elapsed: 0:19:24.\n",
      "  Batch 3,120  of  14,789.    Elapsed: 0:19:39.\n",
      "  Batch 3,160  of  14,789.    Elapsed: 0:19:54.\n",
      "  Batch 3,200  of  14,789.    Elapsed: 0:20:09.\n",
      "  Batch 3,240  of  14,789.    Elapsed: 0:20:25.\n",
      "  Batch 3,280  of  14,789.    Elapsed: 0:20:40.\n",
      "  Batch 3,320  of  14,789.    Elapsed: 0:20:55.\n",
      "  Batch 3,360  of  14,789.    Elapsed: 0:21:10.\n",
      "  Batch 3,400  of  14,789.    Elapsed: 0:21:25.\n",
      "  Batch 3,440  of  14,789.    Elapsed: 0:21:40.\n",
      "  Batch 3,480  of  14,789.    Elapsed: 0:21:55.\n",
      "  Batch 3,520  of  14,789.    Elapsed: 0:22:10.\n",
      "  Batch 3,560  of  14,789.    Elapsed: 0:22:25.\n",
      "  Batch 3,600  of  14,789.    Elapsed: 0:22:40.\n",
      "  Batch 3,640  of  14,789.    Elapsed: 0:22:55.\n",
      "  Batch 3,680  of  14,789.    Elapsed: 0:23:11.\n",
      "  Batch 3,720  of  14,789.    Elapsed: 0:23:26.\n",
      "  Batch 3,760  of  14,789.    Elapsed: 0:23:41.\n",
      "  Batch 3,800  of  14,789.    Elapsed: 0:23:56.\n",
      "  Batch 3,840  of  14,789.    Elapsed: 0:24:11.\n",
      "  Batch 3,880  of  14,789.    Elapsed: 0:24:26.\n",
      "  Batch 3,920  of  14,789.    Elapsed: 0:24:41.\n",
      "  Batch 3,960  of  14,789.    Elapsed: 0:24:56.\n",
      "  Batch 4,000  of  14,789.    Elapsed: 0:25:11.\n",
      "  Batch 4,040  of  14,789.    Elapsed: 0:25:28.\n",
      "  Batch 4,080  of  14,789.    Elapsed: 0:25:43.\n",
      "  Batch 4,120  of  14,789.    Elapsed: 0:25:58.\n",
      "  Batch 4,160  of  14,789.    Elapsed: 0:26:13.\n",
      "  Batch 4,200  of  14,789.    Elapsed: 0:26:28.\n",
      "  Batch 4,240  of  14,789.    Elapsed: 0:26:43.\n",
      "  Batch 4,280  of  14,789.    Elapsed: 0:26:58.\n",
      "  Batch 4,320  of  14,789.    Elapsed: 0:27:14.\n",
      "  Batch 4,360  of  14,789.    Elapsed: 0:27:29.\n",
      "  Batch 4,400  of  14,789.    Elapsed: 0:27:44.\n",
      "  Batch 4,440  of  14,789.    Elapsed: 0:27:59.\n",
      "  Batch 4,480  of  14,789.    Elapsed: 0:28:14.\n",
      "  Batch 4,520  of  14,789.    Elapsed: 0:28:29.\n",
      "  Batch 4,560  of  14,789.    Elapsed: 0:28:44.\n",
      "  Batch 4,600  of  14,789.    Elapsed: 0:28:59.\n",
      "  Batch 4,640  of  14,789.    Elapsed: 0:29:14.\n",
      "  Batch 4,680  of  14,789.    Elapsed: 0:29:29.\n",
      "  Batch 4,720  of  14,789.    Elapsed: 0:29:45.\n",
      "  Batch 4,760  of  14,789.    Elapsed: 0:30:00.\n",
      "  Batch 4,800  of  14,789.    Elapsed: 0:30:15.\n",
      "  Batch 4,840  of  14,789.    Elapsed: 0:30:30.\n",
      "  Batch 4,880  of  14,789.    Elapsed: 0:30:45.\n",
      "  Batch 4,920  of  14,789.    Elapsed: 0:31:00.\n",
      "  Batch 4,960  of  14,789.    Elapsed: 0:31:15.\n",
      "  Batch 5,000  of  14,789.    Elapsed: 0:31:30.\n",
      "  Batch 5,040  of  14,789.    Elapsed: 0:31:45.\n",
      "  Batch 5,080  of  14,789.    Elapsed: 0:32:00.\n",
      "  Batch 5,120  of  14,789.    Elapsed: 0:32:15.\n",
      "  Batch 5,160  of  14,789.    Elapsed: 0:32:31.\n",
      "  Batch 5,200  of  14,789.    Elapsed: 0:32:46.\n",
      "  Batch 5,240  of  14,789.    Elapsed: 0:33:01.\n",
      "  Batch 5,280  of  14,789.    Elapsed: 0:33:16.\n",
      "  Batch 5,320  of  14,789.    Elapsed: 0:33:31.\n",
      "  Batch 5,360  of  14,789.    Elapsed: 0:33:46.\n",
      "  Batch 5,400  of  14,789.    Elapsed: 0:34:01.\n",
      "  Batch 5,440  of  14,789.    Elapsed: 0:34:16.\n",
      "  Batch 5,480  of  14,789.    Elapsed: 0:34:31.\n",
      "  Batch 5,520  of  14,789.    Elapsed: 0:34:46.\n",
      "  Batch 5,560  of  14,789.    Elapsed: 0:35:01.\n",
      "  Batch 5,600  of  14,789.    Elapsed: 0:35:17.\n",
      "  Batch 5,640  of  14,789.    Elapsed: 0:35:32.\n",
      "  Batch 5,680  of  14,789.    Elapsed: 0:35:47.\n",
      "  Batch 5,720  of  14,789.    Elapsed: 0:36:02.\n",
      "  Batch 5,760  of  14,789.    Elapsed: 0:36:17.\n",
      "  Batch 5,800  of  14,789.    Elapsed: 0:36:32.\n",
      "  Batch 5,840  of  14,789.    Elapsed: 0:36:47.\n",
      "  Batch 5,880  of  14,789.    Elapsed: 0:37:02.\n",
      "  Batch 5,920  of  14,789.    Elapsed: 0:37:17.\n",
      "  Batch 5,960  of  14,789.    Elapsed: 0:37:32.\n",
      "  Batch 6,000  of  14,789.    Elapsed: 0:37:47.\n",
      "  Batch 6,040  of  14,789.    Elapsed: 0:38:05.\n",
      "  Batch 6,080  of  14,789.    Elapsed: 0:38:20.\n",
      "  Batch 6,120  of  14,789.    Elapsed: 0:38:35.\n",
      "  Batch 6,160  of  14,789.    Elapsed: 0:38:50.\n",
      "  Batch 6,200  of  14,789.    Elapsed: 0:39:06.\n",
      "  Batch 6,240  of  14,789.    Elapsed: 0:39:21.\n",
      "  Batch 6,280  of  14,789.    Elapsed: 0:39:36.\n",
      "  Batch 6,320  of  14,789.    Elapsed: 0:39:51.\n",
      "  Batch 6,360  of  14,789.    Elapsed: 0:40:06.\n",
      "  Batch 6,400  of  14,789.    Elapsed: 0:40:21.\n",
      "  Batch 6,440  of  14,789.    Elapsed: 0:40:36.\n",
      "  Batch 6,480  of  14,789.    Elapsed: 0:40:51.\n",
      "  Batch 6,520  of  14,789.    Elapsed: 0:41:07.\n",
      "  Batch 6,560  of  14,789.    Elapsed: 0:41:22.\n",
      "  Batch 6,600  of  14,789.    Elapsed: 0:41:37.\n",
      "  Batch 6,640  of  14,789.    Elapsed: 0:41:52.\n",
      "  Batch 6,680  of  14,789.    Elapsed: 0:42:07.\n",
      "  Batch 6,720  of  14,789.    Elapsed: 0:42:22.\n",
      "  Batch 6,760  of  14,789.    Elapsed: 0:42:37.\n",
      "  Batch 6,800  of  14,789.    Elapsed: 0:42:52.\n",
      "  Batch 6,840  of  14,789.    Elapsed: 0:43:07.\n",
      "  Batch 6,880  of  14,789.    Elapsed: 0:43:22.\n",
      "  Batch 6,920  of  14,789.    Elapsed: 0:43:38.\n",
      "  Batch 6,960  of  14,789.    Elapsed: 0:43:53.\n",
      "  Batch 7,000  of  14,789.    Elapsed: 0:44:08.\n",
      "  Batch 7,040  of  14,789.    Elapsed: 0:44:23.\n",
      "  Batch 7,080  of  14,789.    Elapsed: 0:44:38.\n",
      "  Batch 7,120  of  14,789.    Elapsed: 0:44:53.\n",
      "  Batch 7,160  of  14,789.    Elapsed: 0:45:08.\n",
      "  Batch 7,200  of  14,789.    Elapsed: 0:45:23.\n",
      "  Batch 7,240  of  14,789.    Elapsed: 0:45:38.\n",
      "  Batch 7,280  of  14,789.    Elapsed: 0:45:53.\n",
      "  Batch 7,320  of  14,789.    Elapsed: 0:46:08.\n",
      "  Batch 7,360  of  14,789.    Elapsed: 0:46:24.\n",
      "  Batch 7,400  of  14,789.    Elapsed: 0:46:39.\n",
      "  Batch 7,440  of  14,789.    Elapsed: 0:46:54.\n",
      "  Batch 7,480  of  14,789.    Elapsed: 0:47:09.\n",
      "  Batch 7,520  of  14,789.    Elapsed: 0:47:24.\n",
      "  Batch 7,560  of  14,789.    Elapsed: 0:47:39.\n",
      "  Batch 7,600  of  14,789.    Elapsed: 0:47:54.\n",
      "  Batch 7,640  of  14,789.    Elapsed: 0:48:09.\n",
      "  Batch 7,680  of  14,789.    Elapsed: 0:48:24.\n",
      "  Batch 7,720  of  14,789.    Elapsed: 0:48:39.\n",
      "  Batch 7,760  of  14,789.    Elapsed: 0:48:55.\n",
      "  Batch 7,800  of  14,789.    Elapsed: 0:49:10.\n",
      "  Batch 7,840  of  14,789.    Elapsed: 0:49:25.\n",
      "  Batch 7,880  of  14,789.    Elapsed: 0:49:40.\n",
      "  Batch 7,920  of  14,789.    Elapsed: 0:49:55.\n",
      "  Batch 7,960  of  14,789.    Elapsed: 0:50:10.\n",
      "  Batch 8,000  of  14,789.    Elapsed: 0:50:25.\n",
      "  Batch 8,040  of  14,789.    Elapsed: 0:50:42.\n",
      "  Batch 8,080  of  14,789.    Elapsed: 0:50:57.\n",
      "  Batch 8,120  of  14,789.    Elapsed: 0:51:12.\n",
      "  Batch 8,160  of  14,789.    Elapsed: 0:51:27.\n",
      "  Batch 8,200  of  14,789.    Elapsed: 0:51:42.\n",
      "  Batch 8,240  of  14,789.    Elapsed: 0:51:57.\n",
      "  Batch 8,280  of  14,789.    Elapsed: 0:52:12.\n",
      "  Batch 8,320  of  14,789.    Elapsed: 0:52:27.\n",
      "  Batch 8,360  of  14,789.    Elapsed: 0:52:43.\n",
      "  Batch 8,400  of  14,789.    Elapsed: 0:52:58.\n",
      "  Batch 8,440  of  14,789.    Elapsed: 0:53:13.\n",
      "  Batch 8,480  of  14,789.    Elapsed: 0:53:28.\n",
      "  Batch 8,520  of  14,789.    Elapsed: 0:53:43.\n",
      "  Batch 8,560  of  14,789.    Elapsed: 0:53:58.\n",
      "  Batch 8,600  of  14,789.    Elapsed: 0:54:13.\n",
      "  Batch 8,640  of  14,789.    Elapsed: 0:54:28.\n",
      "  Batch 8,680  of  14,789.    Elapsed: 0:54:43.\n",
      "  Batch 8,720  of  14,789.    Elapsed: 0:54:59.\n",
      "  Batch 8,760  of  14,789.    Elapsed: 0:55:14.\n",
      "  Batch 8,800  of  14,789.    Elapsed: 0:55:29.\n",
      "  Batch 8,840  of  14,789.    Elapsed: 0:55:44.\n",
      "  Batch 8,880  of  14,789.    Elapsed: 0:55:59.\n",
      "  Batch 8,920  of  14,789.    Elapsed: 0:56:14.\n",
      "  Batch 8,960  of  14,789.    Elapsed: 0:56:29.\n",
      "  Batch 9,000  of  14,789.    Elapsed: 0:56:44.\n",
      "  Batch 9,040  of  14,789.    Elapsed: 0:56:59.\n",
      "  Batch 9,080  of  14,789.    Elapsed: 0:57:15.\n",
      "  Batch 9,120  of  14,789.    Elapsed: 0:57:30.\n",
      "  Batch 9,160  of  14,789.    Elapsed: 0:57:45.\n",
      "  Batch 9,200  of  14,789.    Elapsed: 0:58:00.\n",
      "  Batch 9,240  of  14,789.    Elapsed: 0:58:15.\n",
      "  Batch 9,280  of  14,789.    Elapsed: 0:58:30.\n",
      "  Batch 9,320  of  14,789.    Elapsed: 0:58:45.\n",
      "  Batch 9,360  of  14,789.    Elapsed: 0:59:00.\n",
      "  Batch 9,400  of  14,789.    Elapsed: 0:59:15.\n",
      "  Batch 9,440  of  14,789.    Elapsed: 0:59:30.\n",
      "  Batch 9,480  of  14,789.    Elapsed: 0:59:45.\n",
      "  Batch 9,520  of  14,789.    Elapsed: 1:00:00.\n",
      "  Batch 9,560  of  14,789.    Elapsed: 1:00:16.\n",
      "  Batch 9,600  of  14,789.    Elapsed: 1:00:31.\n",
      "  Batch 9,640  of  14,789.    Elapsed: 1:00:46.\n",
      "  Batch 9,680  of  14,789.    Elapsed: 1:01:01.\n",
      "  Batch 9,720  of  14,789.    Elapsed: 1:01:16.\n",
      "  Batch 9,760  of  14,789.    Elapsed: 1:01:31.\n",
      "  Batch 9,800  of  14,789.    Elapsed: 1:01:46.\n",
      "  Batch 9,840  of  14,789.    Elapsed: 1:02:01.\n",
      "  Batch 9,880  of  14,789.    Elapsed: 1:02:16.\n",
      "  Batch 9,920  of  14,789.    Elapsed: 1:02:32.\n",
      "  Batch 9,960  of  14,789.    Elapsed: 1:02:47.\n",
      "  Batch 10,000  of  14,789.    Elapsed: 1:03:02.\n",
      "  Batch 10,040  of  14,789.    Elapsed: 1:03:18.\n",
      "  Batch 10,080  of  14,789.    Elapsed: 1:03:33.\n",
      "  Batch 10,120  of  14,789.    Elapsed: 1:03:49.\n",
      "  Batch 10,160  of  14,789.    Elapsed: 1:04:04.\n",
      "  Batch 10,200  of  14,789.    Elapsed: 1:04:19.\n",
      "  Batch 10,240  of  14,789.    Elapsed: 1:04:34.\n",
      "  Batch 10,280  of  14,789.    Elapsed: 1:04:49.\n",
      "  Batch 10,320  of  14,789.    Elapsed: 1:05:04.\n",
      "  Batch 10,360  of  14,789.    Elapsed: 1:05:19.\n",
      "  Batch 10,400  of  14,789.    Elapsed: 1:05:34.\n",
      "  Batch 10,440  of  14,789.    Elapsed: 1:05:49.\n",
      "  Batch 10,480  of  14,789.    Elapsed: 1:06:04.\n",
      "  Batch 10,520  of  14,789.    Elapsed: 1:06:19.\n",
      "  Batch 10,560  of  14,789.    Elapsed: 1:06:35.\n",
      "  Batch 10,600  of  14,789.    Elapsed: 1:06:50.\n",
      "  Batch 10,640  of  14,789.    Elapsed: 1:07:05.\n",
      "  Batch 10,680  of  14,789.    Elapsed: 1:07:20.\n",
      "  Batch 10,720  of  14,789.    Elapsed: 1:07:35.\n",
      "  Batch 10,760  of  14,789.    Elapsed: 1:07:50.\n",
      "  Batch 10,800  of  14,789.    Elapsed: 1:08:05.\n",
      "  Batch 10,840  of  14,789.    Elapsed: 1:08:20.\n",
      "  Batch 10,880  of  14,789.    Elapsed: 1:08:35.\n",
      "  Batch 10,920  of  14,789.    Elapsed: 1:08:50.\n",
      "  Batch 10,960  of  14,789.    Elapsed: 1:09:06.\n",
      "  Batch 11,000  of  14,789.    Elapsed: 1:09:21.\n",
      "  Batch 11,040  of  14,789.    Elapsed: 1:09:36.\n",
      "  Batch 11,080  of  14,789.    Elapsed: 1:09:51.\n",
      "  Batch 11,120  of  14,789.    Elapsed: 1:10:06.\n",
      "  Batch 11,160  of  14,789.    Elapsed: 1:10:21.\n",
      "  Batch 11,200  of  14,789.    Elapsed: 1:10:36.\n",
      "  Batch 11,240  of  14,789.    Elapsed: 1:10:51.\n",
      "  Batch 11,280  of  14,789.    Elapsed: 1:11:06.\n",
      "  Batch 11,320  of  14,789.    Elapsed: 1:11:21.\n",
      "  Batch 11,360  of  14,789.    Elapsed: 1:11:37.\n",
      "  Batch 11,400  of  14,789.    Elapsed: 1:11:52.\n",
      "  Batch 11,440  of  14,789.    Elapsed: 1:12:07.\n",
      "  Batch 11,480  of  14,789.    Elapsed: 1:12:22.\n",
      "  Batch 11,520  of  14,789.    Elapsed: 1:12:37.\n",
      "  Batch 11,560  of  14,789.    Elapsed: 1:12:52.\n",
      "  Batch 11,600  of  14,789.    Elapsed: 1:13:07.\n",
      "  Batch 11,640  of  14,789.    Elapsed: 1:13:22.\n",
      "  Batch 11,680  of  14,789.    Elapsed: 1:13:37.\n",
      "  Batch 11,720  of  14,789.    Elapsed: 1:13:52.\n",
      "  Batch 11,760  of  14,789.    Elapsed: 1:14:07.\n",
      "  Batch 11,800  of  14,789.    Elapsed: 1:14:23.\n",
      "  Batch 11,840  of  14,789.    Elapsed: 1:14:38.\n",
      "  Batch 11,880  of  14,789.    Elapsed: 1:14:53.\n",
      "  Batch 11,920  of  14,789.    Elapsed: 1:15:08.\n",
      "  Batch 11,960  of  14,789.    Elapsed: 1:15:23.\n",
      "  Batch 12,000  of  14,789.    Elapsed: 1:15:38.\n",
      "  Batch 12,040  of  14,789.    Elapsed: 1:15:54.\n",
      "  Batch 12,080  of  14,789.    Elapsed: 1:16:10.\n",
      "  Batch 12,120  of  14,789.    Elapsed: 1:16:25.\n",
      "  Batch 12,160  of  14,789.    Elapsed: 1:16:40.\n",
      "  Batch 12,200  of  14,789.    Elapsed: 1:16:55.\n",
      "  Batch 12,240  of  14,789.    Elapsed: 1:17:10.\n",
      "  Batch 12,280  of  14,789.    Elapsed: 1:17:25.\n",
      "  Batch 12,320  of  14,789.    Elapsed: 1:17:40.\n",
      "  Batch 12,360  of  14,789.    Elapsed: 1:17:55.\n",
      "  Batch 12,400  of  14,789.    Elapsed: 1:18:10.\n",
      "  Batch 12,440  of  14,789.    Elapsed: 1:18:25.\n",
      "  Batch 12,480  of  14,789.    Elapsed: 1:18:40.\n",
      "  Batch 12,520  of  14,789.    Elapsed: 1:18:56.\n",
      "  Batch 12,560  of  14,789.    Elapsed: 1:19:11.\n",
      "  Batch 12,600  of  14,789.    Elapsed: 1:19:26.\n",
      "  Batch 12,640  of  14,789.    Elapsed: 1:19:41.\n",
      "  Batch 12,680  of  14,789.    Elapsed: 1:19:56.\n",
      "  Batch 12,720  of  14,789.    Elapsed: 1:20:11.\n",
      "  Batch 12,760  of  14,789.    Elapsed: 1:20:26.\n",
      "  Batch 12,800  of  14,789.    Elapsed: 1:20:41.\n",
      "  Batch 12,840  of  14,789.    Elapsed: 1:20:56.\n",
      "  Batch 12,880  of  14,789.    Elapsed: 1:21:11.\n",
      "  Batch 12,920  of  14,789.    Elapsed: 1:21:26.\n",
      "  Batch 12,960  of  14,789.    Elapsed: 1:21:42.\n",
      "  Batch 13,000  of  14,789.    Elapsed: 1:21:57.\n",
      "  Batch 13,040  of  14,789.    Elapsed: 1:22:12.\n",
      "  Batch 13,080  of  14,789.    Elapsed: 1:22:27.\n",
      "  Batch 13,120  of  14,789.    Elapsed: 1:22:42.\n",
      "  Batch 13,160  of  14,789.    Elapsed: 1:22:57.\n",
      "  Batch 13,200  of  14,789.    Elapsed: 1:23:12.\n",
      "  Batch 13,240  of  14,789.    Elapsed: 1:23:27.\n",
      "  Batch 13,280  of  14,789.    Elapsed: 1:23:42.\n",
      "  Batch 13,320  of  14,789.    Elapsed: 1:23:57.\n",
      "  Batch 13,360  of  14,789.    Elapsed: 1:24:12.\n",
      "  Batch 13,400  of  14,789.    Elapsed: 1:24:28.\n",
      "  Batch 13,440  of  14,789.    Elapsed: 1:24:43.\n",
      "  Batch 13,480  of  14,789.    Elapsed: 1:24:58.\n",
      "  Batch 13,520  of  14,789.    Elapsed: 1:25:13.\n",
      "  Batch 13,560  of  14,789.    Elapsed: 1:25:28.\n",
      "  Batch 13,600  of  14,789.    Elapsed: 1:25:43.\n",
      "  Batch 13,640  of  14,789.    Elapsed: 1:25:58.\n",
      "  Batch 13,680  of  14,789.    Elapsed: 1:26:13.\n",
      "  Batch 13,720  of  14,789.    Elapsed: 1:26:28.\n",
      "  Batch 13,760  of  14,789.    Elapsed: 1:26:43.\n",
      "  Batch 13,800  of  14,789.    Elapsed: 1:26:58.\n",
      "  Batch 13,840  of  14,789.    Elapsed: 1:27:14.\n",
      "  Batch 13,880  of  14,789.    Elapsed: 1:27:29.\n",
      "  Batch 13,920  of  14,789.    Elapsed: 1:27:44.\n",
      "  Batch 13,960  of  14,789.    Elapsed: 1:27:59.\n",
      "  Batch 14,000  of  14,789.    Elapsed: 1:28:14.\n",
      "  Batch 14,040  of  14,789.    Elapsed: 1:28:31.\n",
      "  Batch 14,080  of  14,789.    Elapsed: 1:28:46.\n",
      "  Batch 14,120  of  14,789.    Elapsed: 1:29:01.\n",
      "  Batch 14,160  of  14,789.    Elapsed: 1:29:16.\n",
      "  Batch 14,200  of  14,789.    Elapsed: 1:29:31.\n",
      "  Batch 14,240  of  14,789.    Elapsed: 1:29:46.\n",
      "  Batch 14,280  of  14,789.    Elapsed: 1:30:01.\n",
      "  Batch 14,320  of  14,789.    Elapsed: 1:30:16.\n",
      "  Batch 14,360  of  14,789.    Elapsed: 1:30:31.\n",
      "  Batch 14,400  of  14,789.    Elapsed: 1:30:46.\n",
      "  Batch 14,440  of  14,789.    Elapsed: 1:31:02.\n",
      "  Batch 14,480  of  14,789.    Elapsed: 1:31:17.\n",
      "  Batch 14,520  of  14,789.    Elapsed: 1:31:32.\n",
      "  Batch 14,560  of  14,789.    Elapsed: 1:31:47.\n",
      "  Batch 14,600  of  14,789.    Elapsed: 1:32:02.\n",
      "  Batch 14,640  of  14,789.    Elapsed: 1:32:17.\n",
      "  Batch 14,680  of  14,789.    Elapsed: 1:32:32.\n",
      "  Batch 14,720  of  14,789.    Elapsed: 1:32:47.\n",
      "  Batch 14,760  of  14,789.    Elapsed: 1:33:02.\n",
      "\n",
      "  Average training loss: 0.12\n",
      "  Training epcoh took: 1:33:13\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.97\n",
      "  Validation Loss: 0.11\n",
      "  Validation took: 0:03:12\n",
      "\n",
      "======== Epoch 2 / 4 ========\n",
      "Training...\n",
      "  Batch    40  of  14,789.    Elapsed: 0:00:15.\n",
      "  Batch    80  of  14,789.    Elapsed: 0:00:30.\n",
      "  Batch   120  of  14,789.    Elapsed: 0:00:45.\n",
      "  Batch   160  of  14,789.    Elapsed: 0:01:00.\n",
      "  Batch   200  of  14,789.    Elapsed: 0:01:16.\n",
      "  Batch   240  of  14,789.    Elapsed: 0:01:31.\n",
      "  Batch   280  of  14,789.    Elapsed: 0:01:46.\n",
      "  Batch   320  of  14,789.    Elapsed: 0:02:01.\n",
      "  Batch   360  of  14,789.    Elapsed: 0:02:16.\n",
      "  Batch   400  of  14,789.    Elapsed: 0:02:31.\n",
      "  Batch   440  of  14,789.    Elapsed: 0:02:46.\n",
      "  Batch   480  of  14,789.    Elapsed: 0:03:01.\n",
      "  Batch   520  of  14,789.    Elapsed: 0:03:16.\n",
      "  Batch   560  of  14,789.    Elapsed: 0:03:31.\n",
      "  Batch   600  of  14,789.    Elapsed: 0:03:46.\n",
      "  Batch   640  of  14,789.    Elapsed: 0:04:01.\n",
      "  Batch   680  of  14,789.    Elapsed: 0:04:17.\n",
      "  Batch   720  of  14,789.    Elapsed: 0:04:32.\n",
      "  Batch   760  of  14,789.    Elapsed: 0:04:47.\n",
      "  Batch   800  of  14,789.    Elapsed: 0:05:02.\n",
      "  Batch   840  of  14,789.    Elapsed: 0:05:17.\n",
      "  Batch   880  of  14,789.    Elapsed: 0:05:32.\n",
      "  Batch   920  of  14,789.    Elapsed: 0:05:47.\n",
      "  Batch   960  of  14,789.    Elapsed: 0:06:02.\n",
      "  Batch 1,000  of  14,789.    Elapsed: 0:06:17.\n",
      "  Batch 1,040  of  14,789.    Elapsed: 0:06:32.\n",
      "  Batch 1,080  of  14,789.    Elapsed: 0:06:47.\n",
      "  Batch 1,120  of  14,789.    Elapsed: 0:07:02.\n",
      "  Batch 1,160  of  14,789.    Elapsed: 0:07:17.\n",
      "  Batch 1,200  of  14,789.    Elapsed: 0:07:33.\n",
      "  Batch 1,240  of  14,789.    Elapsed: 0:07:48.\n",
      "  Batch 1,280  of  14,789.    Elapsed: 0:08:03.\n",
      "  Batch 1,320  of  14,789.    Elapsed: 0:08:18.\n",
      "  Batch 1,360  of  14,789.    Elapsed: 0:08:33.\n",
      "  Batch 1,400  of  14,789.    Elapsed: 0:08:48.\n",
      "  Batch 1,440  of  14,789.    Elapsed: 0:09:03.\n",
      "  Batch 1,480  of  14,789.    Elapsed: 0:09:18.\n",
      "  Batch 1,520  of  14,789.    Elapsed: 0:09:33.\n",
      "  Batch 1,560  of  14,789.    Elapsed: 0:09:48.\n",
      "  Batch 1,600  of  14,789.    Elapsed: 0:10:03.\n",
      "  Batch 1,640  of  14,789.    Elapsed: 0:10:18.\n",
      "  Batch 1,680  of  14,789.    Elapsed: 0:10:33.\n",
      "  Batch 1,720  of  14,789.    Elapsed: 0:10:49.\n",
      "  Batch 1,760  of  14,789.    Elapsed: 0:11:04.\n",
      "  Batch 1,800  of  14,789.    Elapsed: 0:11:19.\n",
      "  Batch 1,840  of  14,789.    Elapsed: 0:11:34.\n",
      "  Batch 1,880  of  14,789.    Elapsed: 0:11:49.\n",
      "  Batch 1,920  of  14,789.    Elapsed: 0:12:04.\n",
      "  Batch 1,960  of  14,789.    Elapsed: 0:12:19.\n",
      "  Batch 2,000  of  14,789.    Elapsed: 0:12:34.\n",
      "  Batch 2,040  of  14,789.    Elapsed: 0:12:51.\n",
      "  Batch 2,080  of  14,789.    Elapsed: 0:13:06.\n",
      "  Batch 2,120  of  14,789.    Elapsed: 0:13:21.\n",
      "  Batch 2,160  of  14,789.    Elapsed: 0:13:36.\n",
      "  Batch 2,200  of  14,789.    Elapsed: 0:13:51.\n",
      "  Batch 2,240  of  14,789.    Elapsed: 0:14:06.\n",
      "  Batch 2,280  of  14,789.    Elapsed: 0:14:21.\n",
      "  Batch 2,320  of  14,789.    Elapsed: 0:14:36.\n",
      "  Batch 2,360  of  14,789.    Elapsed: 0:14:51.\n",
      "  Batch 2,400  of  14,789.    Elapsed: 0:15:06.\n",
      "  Batch 2,440  of  14,789.    Elapsed: 0:15:22.\n",
      "  Batch 2,480  of  14,789.    Elapsed: 0:15:37.\n",
      "  Batch 2,520  of  14,789.    Elapsed: 0:15:52.\n",
      "  Batch 2,560  of  14,789.    Elapsed: 0:16:07.\n",
      "  Batch 2,600  of  14,789.    Elapsed: 0:16:22.\n",
      "  Batch 2,640  of  14,789.    Elapsed: 0:16:37.\n",
      "  Batch 2,680  of  14,789.    Elapsed: 0:16:52.\n",
      "  Batch 2,720  of  14,789.    Elapsed: 0:17:07.\n",
      "  Batch 2,760  of  14,789.    Elapsed: 0:17:22.\n",
      "  Batch 2,800  of  14,789.    Elapsed: 0:17:37.\n",
      "  Batch 2,840  of  14,789.    Elapsed: 0:17:52.\n",
      "  Batch 2,880  of  14,789.    Elapsed: 0:18:08.\n",
      "  Batch 2,920  of  14,789.    Elapsed: 0:18:23.\n",
      "  Batch 2,960  of  14,789.    Elapsed: 0:18:38.\n",
      "  Batch 3,000  of  14,789.    Elapsed: 0:18:53.\n",
      "  Batch 3,040  of  14,789.    Elapsed: 0:19:08.\n",
      "  Batch 3,080  of  14,789.    Elapsed: 0:19:23.\n",
      "  Batch 3,120  of  14,789.    Elapsed: 0:19:38.\n",
      "  Batch 3,160  of  14,789.    Elapsed: 0:19:53.\n",
      "  Batch 3,200  of  14,789.    Elapsed: 0:20:08.\n",
      "  Batch 3,240  of  14,789.    Elapsed: 0:20:23.\n",
      "  Batch 3,280  of  14,789.    Elapsed: 0:20:38.\n",
      "  Batch 3,320  of  14,789.    Elapsed: 0:20:54.\n",
      "  Batch 3,360  of  14,789.    Elapsed: 0:21:09.\n",
      "  Batch 3,400  of  14,789.    Elapsed: 0:21:24.\n",
      "  Batch 3,440  of  14,789.    Elapsed: 0:21:39.\n",
      "  Batch 3,480  of  14,789.    Elapsed: 0:21:54.\n",
      "  Batch 3,520  of  14,789.    Elapsed: 0:22:09.\n",
      "  Batch 3,560  of  14,789.    Elapsed: 0:22:24.\n",
      "  Batch 3,600  of  14,789.    Elapsed: 0:22:39.\n",
      "  Batch 3,640  of  14,789.    Elapsed: 0:22:54.\n",
      "  Batch 3,680  of  14,789.    Elapsed: 0:23:09.\n",
      "  Batch 3,720  of  14,789.    Elapsed: 0:23:25.\n",
      "  Batch 3,760  of  14,789.    Elapsed: 0:23:40.\n",
      "  Batch 3,800  of  14,789.    Elapsed: 0:23:55.\n",
      "  Batch 3,840  of  14,789.    Elapsed: 0:24:10.\n",
      "  Batch 3,880  of  14,789.    Elapsed: 0:24:25.\n",
      "  Batch 3,920  of  14,789.    Elapsed: 0:24:40.\n",
      "  Batch 3,960  of  14,789.    Elapsed: 0:24:55.\n",
      "  Batch 4,000  of  14,789.    Elapsed: 0:25:10.\n",
      "  Batch 4,040  of  14,789.    Elapsed: 0:25:27.\n",
      "  Batch 4,080  of  14,789.    Elapsed: 0:25:42.\n",
      "  Batch 4,120  of  14,789.    Elapsed: 0:25:57.\n",
      "  Batch 4,160  of  14,789.    Elapsed: 0:26:12.\n",
      "  Batch 4,200  of  14,789.    Elapsed: 0:26:27.\n",
      "  Batch 4,240  of  14,789.    Elapsed: 0:26:42.\n",
      "  Batch 4,280  of  14,789.    Elapsed: 0:26:57.\n",
      "  Batch 4,320  of  14,789.    Elapsed: 0:27:12.\n",
      "  Batch 4,360  of  14,789.    Elapsed: 0:27:27.\n",
      "  Batch 4,400  of  14,789.    Elapsed: 0:27:42.\n",
      "  Batch 4,440  of  14,789.    Elapsed: 0:27:58.\n",
      "  Batch 4,480  of  14,789.    Elapsed: 0:28:13.\n",
      "  Batch 4,520  of  14,789.    Elapsed: 0:28:28.\n",
      "  Batch 4,560  of  14,789.    Elapsed: 0:28:43.\n",
      "  Batch 4,600  of  14,789.    Elapsed: 0:28:58.\n",
      "  Batch 4,640  of  14,789.    Elapsed: 0:29:13.\n",
      "  Batch 4,680  of  14,789.    Elapsed: 0:29:28.\n",
      "  Batch 4,720  of  14,789.    Elapsed: 0:29:43.\n",
      "  Batch 4,760  of  14,789.    Elapsed: 0:29:58.\n",
      "  Batch 4,800  of  14,789.    Elapsed: 0:30:13.\n",
      "  Batch 4,840  of  14,789.    Elapsed: 0:30:28.\n",
      "  Batch 4,880  of  14,789.    Elapsed: 0:30:43.\n",
      "  Batch 4,920  of  14,789.    Elapsed: 0:30:59.\n",
      "  Batch 4,960  of  14,789.    Elapsed: 0:31:14.\n",
      "  Batch 5,000  of  14,789.    Elapsed: 0:31:29.\n",
      "  Batch 5,040  of  14,789.    Elapsed: 0:31:44.\n",
      "  Batch 5,080  of  14,789.    Elapsed: 0:31:59.\n",
      "  Batch 5,120  of  14,789.    Elapsed: 0:32:14.\n",
      "  Batch 5,160  of  14,789.    Elapsed: 0:32:29.\n",
      "  Batch 5,200  of  14,789.    Elapsed: 0:32:44.\n",
      "  Batch 5,240  of  14,789.    Elapsed: 0:32:59.\n",
      "  Batch 5,280  of  14,789.    Elapsed: 0:33:14.\n",
      "  Batch 5,320  of  14,789.    Elapsed: 0:33:29.\n",
      "  Batch 5,360  of  14,789.    Elapsed: 0:33:45.\n",
      "  Batch 5,400  of  14,789.    Elapsed: 0:34:00.\n",
      "  Batch 5,440  of  14,789.    Elapsed: 0:34:15.\n",
      "  Batch 5,480  of  14,789.    Elapsed: 0:34:30.\n",
      "  Batch 5,520  of  14,789.    Elapsed: 0:34:45.\n",
      "  Batch 5,560  of  14,789.    Elapsed: 0:35:00.\n",
      "  Batch 5,600  of  14,789.    Elapsed: 0:35:15.\n",
      "  Batch 5,640  of  14,789.    Elapsed: 0:35:30.\n",
      "  Batch 5,680  of  14,789.    Elapsed: 0:35:45.\n",
      "  Batch 5,720  of  14,789.    Elapsed: 0:36:00.\n",
      "  Batch 5,760  of  14,789.    Elapsed: 0:36:15.\n",
      "  Batch 5,800  of  14,789.    Elapsed: 0:36:30.\n",
      "  Batch 5,840  of  14,789.    Elapsed: 0:36:46.\n",
      "  Batch 5,880  of  14,789.    Elapsed: 0:37:01.\n",
      "  Batch 5,920  of  14,789.    Elapsed: 0:37:16.\n",
      "  Batch 5,960  of  14,789.    Elapsed: 0:37:31.\n",
      "  Batch 6,000  of  14,789.    Elapsed: 0:37:46.\n",
      "  Batch 6,040  of  14,789.    Elapsed: 0:38:03.\n",
      "  Batch 6,080  of  14,789.    Elapsed: 0:38:18.\n",
      "  Batch 6,120  of  14,789.    Elapsed: 0:38:33.\n",
      "  Batch 6,160  of  14,789.    Elapsed: 0:38:48.\n",
      "  Batch 6,200  of  14,789.    Elapsed: 0:39:03.\n",
      "  Batch 6,240  of  14,789.    Elapsed: 0:39:18.\n",
      "  Batch 6,280  of  14,789.    Elapsed: 0:39:33.\n",
      "  Batch 6,320  of  14,789.    Elapsed: 0:39:48.\n",
      "  Batch 6,360  of  14,789.    Elapsed: 0:40:03.\n",
      "  Batch 6,400  of  14,789.    Elapsed: 0:40:18.\n",
      "  Batch 6,440  of  14,789.    Elapsed: 0:40:34.\n",
      "  Batch 6,480  of  14,789.    Elapsed: 0:40:49.\n",
      "  Batch 6,520  of  14,789.    Elapsed: 0:41:04.\n",
      "  Batch 6,560  of  14,789.    Elapsed: 0:41:19.\n",
      "  Batch 6,600  of  14,789.    Elapsed: 0:41:34.\n",
      "  Batch 6,640  of  14,789.    Elapsed: 0:41:49.\n",
      "  Batch 6,680  of  14,789.    Elapsed: 0:42:04.\n",
      "  Batch 6,720  of  14,789.    Elapsed: 0:42:19.\n",
      "  Batch 6,760  of  14,789.    Elapsed: 0:42:34.\n",
      "  Batch 6,800  of  14,789.    Elapsed: 0:42:49.\n",
      "  Batch 6,840  of  14,789.    Elapsed: 0:43:04.\n",
      "  Batch 6,880  of  14,789.    Elapsed: 0:43:19.\n",
      "  Batch 6,920  of  14,789.    Elapsed: 0:43:35.\n",
      "  Batch 6,960  of  14,789.    Elapsed: 0:43:50.\n",
      "  Batch 7,000  of  14,789.    Elapsed: 0:44:05.\n",
      "  Batch 7,040  of  14,789.    Elapsed: 0:44:20.\n",
      "  Batch 7,080  of  14,789.    Elapsed: 0:44:35.\n",
      "  Batch 7,120  of  14,789.    Elapsed: 0:44:50.\n",
      "  Batch 7,160  of  14,789.    Elapsed: 0:45:05.\n",
      "  Batch 7,200  of  14,789.    Elapsed: 0:45:20.\n",
      "  Batch 7,240  of  14,789.    Elapsed: 0:45:35.\n",
      "  Batch 7,280  of  14,789.    Elapsed: 0:45:50.\n",
      "  Batch 7,320  of  14,789.    Elapsed: 0:46:05.\n",
      "  Batch 7,360  of  14,789.    Elapsed: 0:46:20.\n",
      "  Batch 7,400  of  14,789.    Elapsed: 0:46:36.\n",
      "  Batch 7,440  of  14,789.    Elapsed: 0:46:51.\n",
      "  Batch 7,480  of  14,789.    Elapsed: 0:47:06.\n",
      "  Batch 7,520  of  14,789.    Elapsed: 0:47:21.\n",
      "  Batch 7,560  of  14,789.    Elapsed: 0:47:36.\n",
      "  Batch 7,600  of  14,789.    Elapsed: 0:47:51.\n",
      "  Batch 7,640  of  14,789.    Elapsed: 0:48:06.\n",
      "  Batch 7,680  of  14,789.    Elapsed: 0:48:21.\n",
      "  Batch 7,720  of  14,789.    Elapsed: 0:48:36.\n",
      "  Batch 7,760  of  14,789.    Elapsed: 0:48:51.\n",
      "  Batch 7,800  of  14,789.    Elapsed: 0:49:07.\n",
      "  Batch 7,840  of  14,789.    Elapsed: 0:49:22.\n",
      "  Batch 7,880  of  14,789.    Elapsed: 0:49:37.\n",
      "  Batch 7,920  of  14,789.    Elapsed: 0:49:52.\n",
      "  Batch 7,960  of  14,789.    Elapsed: 0:50:07.\n",
      "  Batch 8,000  of  14,789.    Elapsed: 0:50:22.\n",
      "  Batch 8,040  of  14,789.    Elapsed: 0:50:39.\n",
      "  Batch 8,080  of  14,789.    Elapsed: 0:50:54.\n",
      "  Batch 8,120  of  14,789.    Elapsed: 0:51:09.\n",
      "  Batch 8,160  of  14,789.    Elapsed: 0:51:24.\n",
      "  Batch 8,200  of  14,789.    Elapsed: 0:51:39.\n",
      "  Batch 8,240  of  14,789.    Elapsed: 0:51:54.\n",
      "  Batch 8,280  of  14,789.    Elapsed: 0:52:09.\n",
      "  Batch 8,320  of  14,789.    Elapsed: 0:52:24.\n",
      "  Batch 8,360  of  14,789.    Elapsed: 0:52:40.\n",
      "  Batch 8,400  of  14,789.    Elapsed: 0:52:55.\n",
      "  Batch 8,440  of  14,789.    Elapsed: 0:53:10.\n",
      "  Batch 8,480  of  14,789.    Elapsed: 0:53:25.\n",
      "  Batch 8,520  of  14,789.    Elapsed: 0:53:40.\n",
      "  Batch 8,560  of  14,789.    Elapsed: 0:53:55.\n",
      "  Batch 8,600  of  14,789.    Elapsed: 0:54:10.\n",
      "  Batch 8,640  of  14,789.    Elapsed: 0:54:25.\n",
      "  Batch 8,680  of  14,789.    Elapsed: 0:54:40.\n",
      "  Batch 8,720  of  14,789.    Elapsed: 0:54:55.\n",
      "  Batch 8,760  of  14,789.    Elapsed: 0:55:10.\n",
      "  Batch 8,800  of  14,789.    Elapsed: 0:55:25.\n",
      "  Batch 8,840  of  14,789.    Elapsed: 0:55:41.\n",
      "  Batch 8,880  of  14,789.    Elapsed: 0:55:56.\n",
      "  Batch 8,920  of  14,789.    Elapsed: 0:56:11.\n",
      "  Batch 8,960  of  14,789.    Elapsed: 0:56:26.\n",
      "  Batch 9,000  of  14,789.    Elapsed: 0:56:41.\n",
      "  Batch 9,040  of  14,789.    Elapsed: 0:56:56.\n",
      "  Batch 9,080  of  14,789.    Elapsed: 0:57:11.\n",
      "  Batch 9,120  of  14,789.    Elapsed: 0:57:26.\n",
      "  Batch 9,160  of  14,789.    Elapsed: 0:57:41.\n",
      "  Batch 9,200  of  14,789.    Elapsed: 0:57:56.\n",
      "  Batch 9,240  of  14,789.    Elapsed: 0:58:11.\n",
      "  Batch 9,280  of  14,789.    Elapsed: 0:58:27.\n",
      "  Batch 9,320  of  14,789.    Elapsed: 0:58:42.\n",
      "  Batch 9,360  of  14,789.    Elapsed: 0:58:57.\n",
      "  Batch 9,400  of  14,789.    Elapsed: 0:59:12.\n",
      "  Batch 9,440  of  14,789.    Elapsed: 0:59:27.\n",
      "  Batch 9,480  of  14,789.    Elapsed: 0:59:42.\n",
      "  Batch 9,520  of  14,789.    Elapsed: 0:59:57.\n",
      "  Batch 9,560  of  14,789.    Elapsed: 1:00:12.\n",
      "  Batch 9,600  of  14,789.    Elapsed: 1:00:27.\n",
      "  Batch 9,640  of  14,789.    Elapsed: 1:00:42.\n",
      "  Batch 9,680  of  14,789.    Elapsed: 1:00:57.\n",
      "  Batch 9,720  of  14,789.    Elapsed: 1:01:13.\n",
      "  Batch 9,760  of  14,789.    Elapsed: 1:01:28.\n",
      "  Batch 9,800  of  14,789.    Elapsed: 1:01:43.\n",
      "  Batch 9,840  of  14,789.    Elapsed: 1:01:58.\n",
      "  Batch 9,880  of  14,789.    Elapsed: 1:02:13.\n",
      "  Batch 9,920  of  14,789.    Elapsed: 1:02:28.\n",
      "  Batch 9,960  of  14,789.    Elapsed: 1:02:43.\n",
      "  Batch 10,000  of  14,789.    Elapsed: 1:02:58.\n",
      "  Batch 10,040  of  14,789.    Elapsed: 1:03:15.\n",
      "  Batch 10,080  of  14,789.    Elapsed: 1:03:30.\n",
      "  Batch 10,120  of  14,789.    Elapsed: 1:03:45.\n",
      "  Batch 10,160  of  14,789.    Elapsed: 1:04:00.\n",
      "  Batch 10,200  of  14,789.    Elapsed: 1:04:15.\n",
      "  Batch 10,240  of  14,789.    Elapsed: 1:04:30.\n",
      "  Batch 10,280  of  14,789.    Elapsed: 1:04:45.\n",
      "  Batch 10,320  of  14,789.    Elapsed: 1:05:00.\n",
      "  Batch 10,360  of  14,789.    Elapsed: 1:05:15.\n",
      "  Batch 10,400  of  14,789.    Elapsed: 1:05:30.\n",
      "  Batch 10,440  of  14,789.    Elapsed: 1:05:46.\n",
      "  Batch 10,480  of  14,789.    Elapsed: 1:06:01.\n",
      "  Batch 10,520  of  14,789.    Elapsed: 1:06:16.\n",
      "  Batch 10,560  of  14,789.    Elapsed: 1:06:31.\n",
      "  Batch 10,600  of  14,789.    Elapsed: 1:06:46.\n",
      "  Batch 10,640  of  14,789.    Elapsed: 1:07:01.\n",
      "  Batch 10,680  of  14,789.    Elapsed: 1:07:16.\n",
      "  Batch 10,720  of  14,789.    Elapsed: 1:07:31.\n",
      "  Batch 10,760  of  14,789.    Elapsed: 1:07:46.\n",
      "  Batch 10,800  of  14,789.    Elapsed: 1:08:01.\n",
      "  Batch 10,840  of  14,789.    Elapsed: 1:08:16.\n",
      "  Batch 10,880  of  14,789.    Elapsed: 1:08:32.\n",
      "  Batch 10,920  of  14,789.    Elapsed: 1:08:47.\n",
      "  Batch 10,960  of  14,789.    Elapsed: 1:09:02.\n",
      "  Batch 11,000  of  14,789.    Elapsed: 1:09:17.\n",
      "  Batch 11,040  of  14,789.    Elapsed: 1:09:32.\n",
      "  Batch 11,080  of  14,789.    Elapsed: 1:09:47.\n",
      "  Batch 11,120  of  14,789.    Elapsed: 1:10:02.\n",
      "  Batch 11,160  of  14,789.    Elapsed: 1:10:17.\n",
      "  Batch 11,200  of  14,789.    Elapsed: 1:10:32.\n",
      "  Batch 11,240  of  14,789.    Elapsed: 1:10:47.\n",
      "  Batch 11,280  of  14,789.    Elapsed: 1:11:02.\n",
      "  Batch 11,320  of  14,789.    Elapsed: 1:11:17.\n",
      "  Batch 11,360  of  14,789.    Elapsed: 1:11:32.\n",
      "  Batch 11,400  of  14,789.    Elapsed: 1:11:48.\n",
      "  Batch 11,440  of  14,789.    Elapsed: 1:12:03.\n",
      "  Batch 11,480  of  14,789.    Elapsed: 1:12:18.\n",
      "  Batch 11,520  of  14,789.    Elapsed: 1:12:33.\n",
      "  Batch 11,560  of  14,789.    Elapsed: 1:12:48.\n",
      "  Batch 11,600  of  14,789.    Elapsed: 1:13:03.\n",
      "  Batch 11,640  of  14,789.    Elapsed: 1:13:18.\n",
      "  Batch 11,680  of  14,789.    Elapsed: 1:13:33.\n",
      "  Batch 11,720  of  14,789.    Elapsed: 1:13:48.\n",
      "  Batch 11,760  of  14,789.    Elapsed: 1:14:03.\n",
      "  Batch 11,800  of  14,789.    Elapsed: 1:14:18.\n",
      "  Batch 11,840  of  14,789.    Elapsed: 1:14:34.\n",
      "  Batch 11,880  of  14,789.    Elapsed: 1:14:49.\n",
      "  Batch 11,920  of  14,789.    Elapsed: 1:15:04.\n",
      "  Batch 11,960  of  14,789.    Elapsed: 1:15:19.\n",
      "  Batch 12,000  of  14,789.    Elapsed: 1:15:34.\n",
      "  Batch 12,040  of  14,789.    Elapsed: 1:15:50.\n",
      "  Batch 12,080  of  14,789.    Elapsed: 1:16:06.\n",
      "  Batch 12,120  of  14,789.    Elapsed: 1:16:21.\n",
      "  Batch 12,160  of  14,789.    Elapsed: 1:16:36.\n",
      "  Batch 12,200  of  14,789.    Elapsed: 1:16:51.\n",
      "  Batch 12,240  of  14,789.    Elapsed: 1:17:06.\n",
      "  Batch 12,280  of  14,789.    Elapsed: 1:17:21.\n",
      "  Batch 12,320  of  14,789.    Elapsed: 1:17:36.\n",
      "  Batch 12,360  of  14,789.    Elapsed: 1:17:51.\n",
      "  Batch 12,400  of  14,789.    Elapsed: 1:18:06.\n",
      "  Batch 12,440  of  14,789.    Elapsed: 1:18:21.\n",
      "  Batch 12,480  of  14,789.    Elapsed: 1:18:36.\n",
      "  Batch 12,520  of  14,789.    Elapsed: 1:18:51.\n",
      "  Batch 12,560  of  14,789.    Elapsed: 1:19:07.\n",
      "  Batch 12,600  of  14,789.    Elapsed: 1:19:22.\n",
      "  Batch 12,640  of  14,789.    Elapsed: 1:19:37.\n",
      "  Batch 12,680  of  14,789.    Elapsed: 1:19:52.\n",
      "  Batch 12,720  of  14,789.    Elapsed: 1:20:07.\n",
      "  Batch 12,760  of  14,789.    Elapsed: 1:20:22.\n",
      "  Batch 12,800  of  14,789.    Elapsed: 1:20:37.\n",
      "  Batch 12,840  of  14,789.    Elapsed: 1:20:52.\n",
      "  Batch 12,880  of  14,789.    Elapsed: 1:21:07.\n",
      "  Batch 12,920  of  14,789.    Elapsed: 1:21:22.\n",
      "  Batch 12,960  of  14,789.    Elapsed: 1:21:37.\n",
      "  Batch 13,000  of  14,789.    Elapsed: 1:21:53.\n",
      "  Batch 13,040  of  14,789.    Elapsed: 1:22:08.\n",
      "  Batch 13,080  of  14,789.    Elapsed: 1:22:23.\n",
      "  Batch 13,120  of  14,789.    Elapsed: 1:22:38.\n",
      "  Batch 13,160  of  14,789.    Elapsed: 1:22:53.\n",
      "  Batch 13,200  of  14,789.    Elapsed: 1:23:08.\n",
      "  Batch 13,240  of  14,789.    Elapsed: 1:23:23.\n",
      "  Batch 13,280  of  14,789.    Elapsed: 1:23:38.\n",
      "  Batch 13,320  of  14,789.    Elapsed: 1:23:53.\n",
      "  Batch 13,360  of  14,789.    Elapsed: 1:24:08.\n",
      "  Batch 13,400  of  14,789.    Elapsed: 1:24:23.\n",
      "  Batch 13,440  of  14,789.    Elapsed: 1:24:38.\n",
      "  Batch 13,480  of  14,789.    Elapsed: 1:24:54.\n",
      "  Batch 13,520  of  14,789.    Elapsed: 1:25:09.\n",
      "  Batch 13,560  of  14,789.    Elapsed: 1:25:24.\n",
      "  Batch 13,600  of  14,789.    Elapsed: 1:25:39.\n",
      "  Batch 13,640  of  14,789.    Elapsed: 1:25:54.\n",
      "  Batch 13,680  of  14,789.    Elapsed: 1:26:09.\n",
      "  Batch 13,720  of  14,789.    Elapsed: 1:26:24.\n",
      "  Batch 13,760  of  14,789.    Elapsed: 1:26:39.\n",
      "  Batch 13,800  of  14,789.    Elapsed: 1:26:54.\n",
      "  Batch 13,840  of  14,789.    Elapsed: 1:27:09.\n",
      "  Batch 13,880  of  14,789.    Elapsed: 1:27:25.\n",
      "  Batch 13,920  of  14,789.    Elapsed: 1:27:40.\n",
      "  Batch 13,960  of  14,789.    Elapsed: 1:27:55.\n",
      "  Batch 14,000  of  14,789.    Elapsed: 1:28:10.\n",
      "  Batch 14,040  of  14,789.    Elapsed: 1:28:27.\n",
      "  Batch 14,080  of  14,789.    Elapsed: 1:28:42.\n",
      "  Batch 14,120  of  14,789.    Elapsed: 1:28:57.\n",
      "  Batch 14,160  of  14,789.    Elapsed: 1:29:12.\n",
      "  Batch 14,200  of  14,789.    Elapsed: 1:29:27.\n",
      "  Batch 14,240  of  14,789.    Elapsed: 1:29:42.\n",
      "  Batch 14,280  of  14,789.    Elapsed: 1:29:57.\n",
      "  Batch 14,320  of  14,789.    Elapsed: 1:30:12.\n",
      "  Batch 14,360  of  14,789.    Elapsed: 1:30:27.\n",
      "  Batch 14,400  of  14,789.    Elapsed: 1:30:42.\n",
      "  Batch 14,440  of  14,789.    Elapsed: 1:30:58.\n",
      "  Batch 14,480  of  14,789.    Elapsed: 1:31:13.\n",
      "  Batch 14,520  of  14,789.    Elapsed: 1:31:28.\n",
      "  Batch 14,560  of  14,789.    Elapsed: 1:31:43.\n",
      "  Batch 14,600  of  14,789.    Elapsed: 1:31:58.\n",
      "  Batch 14,640  of  14,789.    Elapsed: 1:32:13.\n",
      "  Batch 14,680  of  14,789.    Elapsed: 1:32:28.\n",
      "  Batch 14,720  of  14,789.    Elapsed: 1:32:43.\n",
      "  Batch 14,760  of  14,789.    Elapsed: 1:32:58.\n",
      "\n",
      "  Average training loss: 0.08\n",
      "  Training epcoh took: 1:33:09\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.98\n",
      "  Validation Loss: 0.08\n",
      "  Validation took: 0:03:12\n",
      "\n",
      "======== Epoch 3 / 4 ========\n",
      "Training...\n",
      "  Batch    40  of  14,789.    Elapsed: 0:00:15.\n",
      "  Batch    80  of  14,789.    Elapsed: 0:00:30.\n",
      "  Batch   120  of  14,789.    Elapsed: 0:00:45.\n",
      "  Batch   160  of  14,789.    Elapsed: 0:01:00.\n",
      "  Batch   200  of  14,789.    Elapsed: 0:01:15.\n",
      "  Batch   240  of  14,789.    Elapsed: 0:01:30.\n",
      "  Batch   280  of  14,789.    Elapsed: 0:01:46.\n",
      "  Batch   320  of  14,789.    Elapsed: 0:02:01.\n",
      "  Batch   360  of  14,789.    Elapsed: 0:02:16.\n",
      "  Batch   400  of  14,789.    Elapsed: 0:02:31.\n",
      "  Batch   440  of  14,789.    Elapsed: 0:02:46.\n",
      "  Batch   480  of  14,789.    Elapsed: 0:03:01.\n",
      "  Batch   520  of  14,789.    Elapsed: 0:03:16.\n",
      "  Batch   560  of  14,789.    Elapsed: 0:03:31.\n",
      "  Batch   600  of  14,789.    Elapsed: 0:03:46.\n",
      "  Batch   640  of  14,789.    Elapsed: 0:04:01.\n",
      "  Batch   680  of  14,789.    Elapsed: 0:04:16.\n",
      "  Batch   720  of  14,789.    Elapsed: 0:04:31.\n",
      "  Batch   760  of  14,789.    Elapsed: 0:04:46.\n",
      "  Batch   800  of  14,789.    Elapsed: 0:05:02.\n",
      "  Batch   840  of  14,789.    Elapsed: 0:05:17.\n",
      "  Batch   880  of  14,789.    Elapsed: 0:05:32.\n",
      "  Batch   920  of  14,789.    Elapsed: 0:05:47.\n",
      "  Batch   960  of  14,789.    Elapsed: 0:06:02.\n",
      "  Batch 1,000  of  14,789.    Elapsed: 0:06:17.\n",
      "  Batch 1,040  of  14,789.    Elapsed: 0:06:32.\n",
      "  Batch 1,080  of  14,789.    Elapsed: 0:06:47.\n",
      "  Batch 1,120  of  14,789.    Elapsed: 0:07:02.\n",
      "  Batch 1,160  of  14,789.    Elapsed: 0:07:17.\n",
      "  Batch 1,200  of  14,789.    Elapsed: 0:07:32.\n",
      "  Batch 1,240  of  14,789.    Elapsed: 0:07:47.\n",
      "  Batch 1,280  of  14,789.    Elapsed: 0:08:02.\n",
      "  Batch 1,320  of  14,789.    Elapsed: 0:08:17.\n",
      "  Batch 1,360  of  14,789.    Elapsed: 0:08:33.\n",
      "  Batch 1,400  of  14,789.    Elapsed: 0:08:48.\n",
      "  Batch 1,440  of  14,789.    Elapsed: 0:09:03.\n",
      "  Batch 1,480  of  14,789.    Elapsed: 0:09:18.\n",
      "  Batch 1,520  of  14,789.    Elapsed: 0:09:33.\n",
      "  Batch 1,560  of  14,789.    Elapsed: 0:09:48.\n",
      "  Batch 1,600  of  14,789.    Elapsed: 0:10:03.\n",
      "  Batch 1,640  of  14,789.    Elapsed: 0:10:18.\n",
      "  Batch 1,680  of  14,789.    Elapsed: 0:10:33.\n",
      "  Batch 1,720  of  14,789.    Elapsed: 0:10:48.\n",
      "  Batch 1,760  of  14,789.    Elapsed: 0:11:03.\n",
      "  Batch 1,800  of  14,789.    Elapsed: 0:11:18.\n",
      "  Batch 1,840  of  14,789.    Elapsed: 0:11:33.\n",
      "  Batch 1,880  of  14,789.    Elapsed: 0:11:48.\n",
      "  Batch 1,920  of  14,789.    Elapsed: 0:12:04.\n",
      "  Batch 1,960  of  14,789.    Elapsed: 0:12:19.\n",
      "  Batch 2,000  of  14,789.    Elapsed: 0:12:34.\n",
      "  Batch 2,040  of  14,789.    Elapsed: 0:12:50.\n",
      "  Batch 2,080  of  14,789.    Elapsed: 0:13:05.\n",
      "  Batch 2,120  of  14,789.    Elapsed: 0:13:20.\n",
      "  Batch 2,160  of  14,789.    Elapsed: 0:13:35.\n",
      "  Batch 2,200  of  14,789.    Elapsed: 0:13:50.\n",
      "  Batch 2,240  of  14,789.    Elapsed: 0:14:06.\n",
      "  Batch 2,280  of  14,789.    Elapsed: 0:14:21.\n",
      "  Batch 2,320  of  14,789.    Elapsed: 0:14:36.\n",
      "  Batch 2,360  of  14,789.    Elapsed: 0:14:51.\n",
      "  Batch 2,400  of  14,789.    Elapsed: 0:15:06.\n",
      "  Batch 2,440  of  14,789.    Elapsed: 0:15:21.\n",
      "  Batch 2,480  of  14,789.    Elapsed: 0:15:36.\n",
      "  Batch 2,520  of  14,789.    Elapsed: 0:15:51.\n",
      "  Batch 2,560  of  14,789.    Elapsed: 0:16:06.\n",
      "  Batch 2,600  of  14,789.    Elapsed: 0:16:21.\n",
      "  Batch 2,640  of  14,789.    Elapsed: 0:16:36.\n",
      "  Batch 2,680  of  14,789.    Elapsed: 0:16:51.\n",
      "  Batch 2,720  of  14,789.    Elapsed: 0:17:07.\n",
      "  Batch 2,760  of  14,789.    Elapsed: 0:17:22.\n",
      "  Batch 2,800  of  14,789.    Elapsed: 0:17:37.\n",
      "  Batch 2,840  of  14,789.    Elapsed: 0:17:52.\n",
      "  Batch 2,880  of  14,789.    Elapsed: 0:18:07.\n",
      "  Batch 2,920  of  14,789.    Elapsed: 0:18:22.\n",
      "  Batch 2,960  of  14,789.    Elapsed: 0:18:37.\n",
      "  Batch 3,000  of  14,789.    Elapsed: 0:18:52.\n",
      "  Batch 3,040  of  14,789.    Elapsed: 0:19:07.\n",
      "  Batch 3,080  of  14,789.    Elapsed: 0:19:22.\n",
      "  Batch 3,120  of  14,789.    Elapsed: 0:19:37.\n",
      "  Batch 3,160  of  14,789.    Elapsed: 0:19:52.\n",
      "  Batch 3,200  of  14,789.    Elapsed: 0:20:07.\n",
      "  Batch 3,240  of  14,789.    Elapsed: 0:20:23.\n",
      "  Batch 3,280  of  14,789.    Elapsed: 0:20:38.\n",
      "  Batch 3,320  of  14,789.    Elapsed: 0:20:53.\n",
      "  Batch 3,360  of  14,789.    Elapsed: 0:21:08.\n",
      "  Batch 3,400  of  14,789.    Elapsed: 0:21:23.\n",
      "  Batch 3,440  of  14,789.    Elapsed: 0:21:38.\n",
      "  Batch 3,480  of  14,789.    Elapsed: 0:21:53.\n",
      "  Batch 3,520  of  14,789.    Elapsed: 0:22:08.\n",
      "  Batch 3,560  of  14,789.    Elapsed: 0:22:23.\n",
      "  Batch 3,600  of  14,789.    Elapsed: 0:22:38.\n",
      "  Batch 3,640  of  14,789.    Elapsed: 0:22:53.\n",
      "  Batch 3,680  of  14,789.    Elapsed: 0:23:08.\n",
      "  Batch 3,720  of  14,789.    Elapsed: 0:23:23.\n",
      "  Batch 3,760  of  14,789.    Elapsed: 0:23:39.\n",
      "  Batch 3,800  of  14,789.    Elapsed: 0:23:54.\n",
      "  Batch 3,840  of  14,789.    Elapsed: 0:24:09.\n",
      "  Batch 3,880  of  14,789.    Elapsed: 0:24:24.\n",
      "  Batch 3,920  of  14,789.    Elapsed: 0:24:39.\n",
      "  Batch 3,960  of  14,789.    Elapsed: 0:24:54.\n",
      "  Batch 4,000  of  14,789.    Elapsed: 0:25:09.\n",
      "  Batch 4,040  of  14,789.    Elapsed: 0:25:26.\n",
      "  Batch 4,080  of  14,789.    Elapsed: 0:25:41.\n",
      "  Batch 4,120  of  14,789.    Elapsed: 0:25:56.\n",
      "  Batch 4,160  of  14,789.    Elapsed: 0:26:11.\n",
      "  Batch 4,200  of  14,789.    Elapsed: 0:26:26.\n",
      "  Batch 4,240  of  14,789.    Elapsed: 0:26:41.\n",
      "  Batch 4,280  of  14,789.    Elapsed: 0:26:56.\n",
      "  Batch 4,320  of  14,789.    Elapsed: 0:27:11.\n",
      "  Batch 4,360  of  14,789.    Elapsed: 0:27:26.\n",
      "  Batch 4,400  of  14,789.    Elapsed: 0:27:41.\n",
      "  Batch 4,440  of  14,789.    Elapsed: 0:27:56.\n",
      "  Batch 4,480  of  14,789.    Elapsed: 0:28:12.\n",
      "  Batch 4,520  of  14,789.    Elapsed: 0:28:27.\n",
      "  Batch 4,560  of  14,789.    Elapsed: 0:28:42.\n",
      "  Batch 4,600  of  14,789.    Elapsed: 0:28:57.\n",
      "  Batch 4,640  of  14,789.    Elapsed: 0:29:12.\n",
      "  Batch 4,680  of  14,789.    Elapsed: 0:29:27.\n",
      "  Batch 4,720  of  14,789.    Elapsed: 0:29:42.\n",
      "  Batch 4,760  of  14,789.    Elapsed: 0:29:57.\n",
      "  Batch 4,800  of  14,789.    Elapsed: 0:30:12.\n",
      "  Batch 4,840  of  14,789.    Elapsed: 0:30:27.\n",
      "  Batch 4,880  of  14,789.    Elapsed: 0:30:42.\n",
      "  Batch 4,920  of  14,789.    Elapsed: 0:30:57.\n",
      "  Batch 4,960  of  14,789.    Elapsed: 0:31:13.\n",
      "  Batch 5,000  of  14,789.    Elapsed: 0:31:28.\n",
      "  Batch 5,040  of  14,789.    Elapsed: 0:31:43.\n",
      "  Batch 5,080  of  14,789.    Elapsed: 0:31:58.\n",
      "  Batch 5,120  of  14,789.    Elapsed: 0:32:13.\n",
      "  Batch 5,160  of  14,789.    Elapsed: 0:32:28.\n",
      "  Batch 5,200  of  14,789.    Elapsed: 0:32:43.\n",
      "  Batch 5,240  of  14,789.    Elapsed: 0:32:58.\n",
      "  Batch 5,280  of  14,789.    Elapsed: 0:33:13.\n",
      "  Batch 5,320  of  14,789.    Elapsed: 0:33:28.\n",
      "  Batch 5,360  of  14,789.    Elapsed: 0:33:43.\n",
      "  Batch 5,400  of  14,789.    Elapsed: 0:33:58.\n",
      "  Batch 5,440  of  14,789.    Elapsed: 0:34:13.\n",
      "  Batch 5,480  of  14,789.    Elapsed: 0:34:29.\n",
      "  Batch 5,520  of  14,789.    Elapsed: 0:34:44.\n",
      "  Batch 5,560  of  14,789.    Elapsed: 0:34:59.\n",
      "  Batch 5,600  of  14,789.    Elapsed: 0:35:14.\n",
      "  Batch 5,640  of  14,789.    Elapsed: 0:35:29.\n",
      "  Batch 5,680  of  14,789.    Elapsed: 0:35:44.\n",
      "  Batch 5,720  of  14,789.    Elapsed: 0:35:59.\n",
      "  Batch 5,760  of  14,789.    Elapsed: 0:36:14.\n",
      "  Batch 5,800  of  14,789.    Elapsed: 0:36:29.\n",
      "  Batch 5,840  of  14,789.    Elapsed: 0:36:44.\n",
      "  Batch 5,880  of  14,789.    Elapsed: 0:36:59.\n",
      "  Batch 5,920  of  14,789.    Elapsed: 0:37:14.\n",
      "  Batch 5,960  of  14,789.    Elapsed: 0:37:30.\n",
      "  Batch 6,000  of  14,789.    Elapsed: 0:37:45.\n",
      "  Batch 6,040  of  14,789.    Elapsed: 0:38:01.\n",
      "  Batch 6,080  of  14,789.    Elapsed: 0:38:16.\n",
      "  Batch 6,120  of  14,789.    Elapsed: 0:38:31.\n",
      "  Batch 6,160  of  14,789.    Elapsed: 0:38:46.\n",
      "  Batch 6,200  of  14,789.    Elapsed: 0:39:02.\n",
      "  Batch 6,240  of  14,789.    Elapsed: 0:39:17.\n",
      "  Batch 6,280  of  14,789.    Elapsed: 0:39:32.\n",
      "  Batch 6,320  of  14,789.    Elapsed: 0:39:47.\n",
      "  Batch 6,360  of  14,789.    Elapsed: 0:40:02.\n",
      "  Batch 6,400  of  14,789.    Elapsed: 0:40:17.\n",
      "  Batch 6,440  of  14,789.    Elapsed: 0:40:32.\n",
      "  Batch 6,480  of  14,789.    Elapsed: 0:40:47.\n",
      "  Batch 6,520  of  14,789.    Elapsed: 0:41:02.\n",
      "  Batch 6,560  of  14,789.    Elapsed: 0:41:17.\n",
      "  Batch 6,600  of  14,789.    Elapsed: 0:41:32.\n",
      "  Batch 6,640  of  14,789.    Elapsed: 0:41:47.\n",
      "  Batch 6,680  of  14,789.    Elapsed: 0:42:03.\n",
      "  Batch 6,720  of  14,789.    Elapsed: 0:42:18.\n",
      "  Batch 6,760  of  14,789.    Elapsed: 0:42:33.\n",
      "  Batch 6,800  of  14,789.    Elapsed: 0:42:48.\n",
      "  Batch 6,840  of  14,789.    Elapsed: 0:43:03.\n",
      "  Batch 6,880  of  14,789.    Elapsed: 0:43:18.\n",
      "  Batch 6,920  of  14,789.    Elapsed: 0:43:33.\n",
      "  Batch 6,960  of  14,789.    Elapsed: 0:43:48.\n",
      "  Batch 7,000  of  14,789.    Elapsed: 0:44:03.\n",
      "  Batch 7,040  of  14,789.    Elapsed: 0:44:18.\n",
      "  Batch 7,080  of  14,789.    Elapsed: 0:44:33.\n",
      "  Batch 7,120  of  14,789.    Elapsed: 0:44:48.\n",
      "  Batch 7,160  of  14,789.    Elapsed: 0:45:04.\n",
      "  Batch 7,200  of  14,789.    Elapsed: 0:45:19.\n",
      "  Batch 7,240  of  14,789.    Elapsed: 0:45:34.\n",
      "  Batch 7,280  of  14,789.    Elapsed: 0:45:49.\n",
      "  Batch 7,320  of  14,789.    Elapsed: 0:46:04.\n",
      "  Batch 7,360  of  14,789.    Elapsed: 0:46:19.\n",
      "  Batch 7,400  of  14,789.    Elapsed: 0:46:34.\n",
      "  Batch 7,440  of  14,789.    Elapsed: 0:46:49.\n",
      "  Batch 7,480  of  14,789.    Elapsed: 0:47:04.\n",
      "  Batch 7,520  of  14,789.    Elapsed: 0:47:19.\n",
      "  Batch 7,560  of  14,789.    Elapsed: 0:47:34.\n",
      "  Batch 7,600  of  14,789.    Elapsed: 0:47:49.\n",
      "  Batch 7,640  of  14,789.    Elapsed: 0:48:05.\n",
      "  Batch 7,680  of  14,789.    Elapsed: 0:48:20.\n",
      "  Batch 7,720  of  14,789.    Elapsed: 0:48:35.\n",
      "  Batch 7,760  of  14,789.    Elapsed: 0:48:50.\n",
      "  Batch 7,800  of  14,789.    Elapsed: 0:49:05.\n",
      "  Batch 7,840  of  14,789.    Elapsed: 0:49:20.\n",
      "  Batch 7,880  of  14,789.    Elapsed: 0:49:35.\n",
      "  Batch 7,920  of  14,789.    Elapsed: 0:49:50.\n",
      "  Batch 7,960  of  14,789.    Elapsed: 0:50:05.\n",
      "  Batch 8,000  of  14,789.    Elapsed: 0:50:20.\n",
      "  Batch 8,040  of  14,789.    Elapsed: 0:50:37.\n",
      "  Batch 8,080  of  14,789.    Elapsed: 0:50:52.\n",
      "  Batch 8,120  of  14,789.    Elapsed: 0:51:07.\n",
      "  Batch 8,160  of  14,789.    Elapsed: 0:51:22.\n",
      "  Batch 8,200  of  14,789.    Elapsed: 0:51:37.\n",
      "  Batch 8,240  of  14,789.    Elapsed: 0:51:52.\n",
      "  Batch 8,280  of  14,789.    Elapsed: 0:52:07.\n",
      "  Batch 8,320  of  14,789.    Elapsed: 0:52:22.\n",
      "  Batch 8,360  of  14,789.    Elapsed: 0:52:38.\n",
      "  Batch 8,400  of  14,789.    Elapsed: 0:52:53.\n",
      "  Batch 8,440  of  14,789.    Elapsed: 0:53:08.\n",
      "  Batch 8,480  of  14,789.    Elapsed: 0:53:23.\n",
      "  Batch 8,520  of  14,789.    Elapsed: 0:53:38.\n",
      "  Batch 8,560  of  14,789.    Elapsed: 0:53:53.\n",
      "  Batch 8,600  of  14,789.    Elapsed: 0:54:08.\n",
      "  Batch 8,640  of  14,789.    Elapsed: 0:54:23.\n",
      "  Batch 8,680  of  14,789.    Elapsed: 0:54:38.\n",
      "  Batch 8,720  of  14,789.    Elapsed: 0:54:53.\n",
      "  Batch 8,760  of  14,789.    Elapsed: 0:55:08.\n",
      "  Batch 8,800  of  14,789.    Elapsed: 0:55:24.\n",
      "  Batch 8,840  of  14,789.    Elapsed: 0:55:39.\n",
      "  Batch 8,880  of  14,789.    Elapsed: 0:55:54.\n",
      "  Batch 8,920  of  14,789.    Elapsed: 0:56:09.\n",
      "  Batch 8,960  of  14,789.    Elapsed: 0:56:24.\n",
      "  Batch 9,000  of  14,789.    Elapsed: 0:56:39.\n",
      "  Batch 9,040  of  14,789.    Elapsed: 0:56:54.\n",
      "  Batch 9,080  of  14,789.    Elapsed: 0:57:09.\n",
      "  Batch 9,120  of  14,789.    Elapsed: 0:57:24.\n",
      "  Batch 9,160  of  14,789.    Elapsed: 0:57:39.\n",
      "  Batch 9,200  of  14,789.    Elapsed: 0:57:54.\n",
      "  Batch 9,240  of  14,789.    Elapsed: 0:58:10.\n",
      "  Batch 9,280  of  14,789.    Elapsed: 0:58:25.\n",
      "  Batch 9,320  of  14,789.    Elapsed: 0:58:40.\n",
      "  Batch 9,360  of  14,789.    Elapsed: 0:58:55.\n",
      "  Batch 9,400  of  14,789.    Elapsed: 0:59:10.\n",
      "  Batch 9,440  of  14,789.    Elapsed: 0:59:25.\n",
      "  Batch 9,480  of  14,789.    Elapsed: 0:59:40.\n",
      "  Batch 9,520  of  14,789.    Elapsed: 0:59:55.\n",
      "  Batch 9,560  of  14,789.    Elapsed: 1:00:10.\n",
      "  Batch 9,600  of  14,789.    Elapsed: 1:00:25.\n",
      "  Batch 9,640  of  14,789.    Elapsed: 1:00:41.\n",
      "  Batch 9,680  of  14,789.    Elapsed: 1:00:56.\n",
      "  Batch 9,720  of  14,789.    Elapsed: 1:01:11.\n",
      "  Batch 9,760  of  14,789.    Elapsed: 1:01:26.\n",
      "  Batch 9,800  of  14,789.    Elapsed: 1:01:41.\n",
      "  Batch 9,840  of  14,789.    Elapsed: 1:01:56.\n",
      "  Batch 9,880  of  14,789.    Elapsed: 1:02:11.\n",
      "  Batch 9,920  of  14,789.    Elapsed: 1:02:26.\n",
      "  Batch 9,960  of  14,789.    Elapsed: 1:02:41.\n",
      "  Batch 10,000  of  14,789.    Elapsed: 1:02:56.\n",
      "  Batch 10,040  of  14,789.    Elapsed: 1:03:13.\n",
      "  Batch 10,080  of  14,789.    Elapsed: 1:03:28.\n",
      "  Batch 10,120  of  14,789.    Elapsed: 1:03:43.\n",
      "  Batch 10,160  of  14,789.    Elapsed: 1:03:58.\n",
      "  Batch 10,200  of  14,789.    Elapsed: 1:04:13.\n",
      "  Batch 10,240  of  14,789.    Elapsed: 1:04:28.\n",
      "  Batch 10,280  of  14,789.    Elapsed: 1:04:43.\n",
      "  Batch 10,320  of  14,789.    Elapsed: 1:04:58.\n",
      "  Batch 10,360  of  14,789.    Elapsed: 1:05:14.\n",
      "  Batch 10,400  of  14,789.    Elapsed: 1:05:29.\n",
      "  Batch 10,440  of  14,789.    Elapsed: 1:05:44.\n",
      "  Batch 10,480  of  14,789.    Elapsed: 1:05:59.\n",
      "  Batch 10,520  of  14,789.    Elapsed: 1:06:14.\n",
      "  Batch 10,560  of  14,789.    Elapsed: 1:06:29.\n",
      "  Batch 10,600  of  14,789.    Elapsed: 1:06:44.\n",
      "  Batch 10,640  of  14,789.    Elapsed: 1:06:59.\n",
      "  Batch 10,680  of  14,789.    Elapsed: 1:07:14.\n",
      "  Batch 10,720  of  14,789.    Elapsed: 1:07:29.\n",
      "  Batch 10,760  of  14,789.    Elapsed: 1:07:44.\n",
      "  Batch 10,800  of  14,789.    Elapsed: 1:07:59.\n",
      "  Batch 10,840  of  14,789.    Elapsed: 1:08:15.\n",
      "  Batch 10,880  of  14,789.    Elapsed: 1:08:30.\n",
      "  Batch 10,920  of  14,789.    Elapsed: 1:08:45.\n",
      "  Batch 10,960  of  14,789.    Elapsed: 1:09:00.\n",
      "  Batch 11,000  of  14,789.    Elapsed: 1:09:15.\n",
      "  Batch 11,040  of  14,789.    Elapsed: 1:09:30.\n",
      "  Batch 11,080  of  14,789.    Elapsed: 1:09:45.\n",
      "  Batch 11,120  of  14,789.    Elapsed: 1:10:00.\n",
      "  Batch 11,160  of  14,789.    Elapsed: 1:10:15.\n",
      "  Batch 11,200  of  14,789.    Elapsed: 1:10:30.\n",
      "  Batch 11,240  of  14,789.    Elapsed: 1:10:45.\n",
      "  Batch 11,280  of  14,789.    Elapsed: 1:11:00.\n",
      "  Batch 11,320  of  14,789.    Elapsed: 1:11:15.\n",
      "  Batch 11,360  of  14,789.    Elapsed: 1:11:31.\n",
      "  Batch 11,400  of  14,789.    Elapsed: 1:11:46.\n",
      "  Batch 11,440  of  14,789.    Elapsed: 1:12:01.\n",
      "  Batch 11,480  of  14,789.    Elapsed: 1:12:16.\n",
      "  Batch 11,520  of  14,789.    Elapsed: 1:12:31.\n",
      "  Batch 11,560  of  14,789.    Elapsed: 1:12:46.\n",
      "  Batch 11,600  of  14,789.    Elapsed: 1:13:01.\n",
      "  Batch 11,640  of  14,789.    Elapsed: 1:13:16.\n",
      "  Batch 11,680  of  14,789.    Elapsed: 1:13:31.\n",
      "  Batch 11,720  of  14,789.    Elapsed: 1:13:46.\n",
      "  Batch 11,760  of  14,789.    Elapsed: 1:14:01.\n",
      "  Batch 11,800  of  14,789.    Elapsed: 1:14:16.\n",
      "  Batch 11,840  of  14,789.    Elapsed: 1:14:32.\n",
      "  Batch 11,880  of  14,789.    Elapsed: 1:14:47.\n",
      "  Batch 11,920  of  14,789.    Elapsed: 1:15:02.\n",
      "  Batch 11,960  of  14,789.    Elapsed: 1:15:17.\n",
      "  Batch 12,000  of  14,789.    Elapsed: 1:15:32.\n",
      "  Batch 12,040  of  14,789.    Elapsed: 1:15:48.\n",
      "  Batch 12,080  of  14,789.    Elapsed: 1:16:04.\n",
      "  Batch 12,120  of  14,789.    Elapsed: 1:16:19.\n",
      "  Batch 12,160  of  14,789.    Elapsed: 1:16:34.\n",
      "  Batch 12,200  of  14,789.    Elapsed: 1:16:49.\n",
      "  Batch 12,240  of  14,789.    Elapsed: 1:17:04.\n",
      "  Batch 12,280  of  14,789.    Elapsed: 1:17:19.\n",
      "  Batch 12,320  of  14,789.    Elapsed: 1:17:34.\n",
      "  Batch 12,360  of  14,789.    Elapsed: 1:17:49.\n",
      "  Batch 12,400  of  14,789.    Elapsed: 1:18:04.\n",
      "  Batch 12,440  of  14,789.    Elapsed: 1:18:19.\n",
      "  Batch 12,480  of  14,789.    Elapsed: 1:18:34.\n",
      "  Batch 12,520  of  14,789.    Elapsed: 1:18:49.\n",
      "  Batch 12,560  of  14,789.    Elapsed: 1:19:05.\n",
      "  Batch 12,600  of  14,789.    Elapsed: 1:19:20.\n",
      "  Batch 12,640  of  14,789.    Elapsed: 1:19:35.\n",
      "  Batch 12,680  of  14,789.    Elapsed: 1:19:50.\n",
      "  Batch 12,720  of  14,789.    Elapsed: 1:20:05.\n",
      "  Batch 12,760  of  14,789.    Elapsed: 1:20:20.\n",
      "  Batch 12,800  of  14,789.    Elapsed: 1:20:35.\n",
      "  Batch 12,840  of  14,789.    Elapsed: 1:20:50.\n",
      "  Batch 12,880  of  14,789.    Elapsed: 1:21:05.\n",
      "  Batch 12,920  of  14,789.    Elapsed: 1:21:20.\n",
      "  Batch 12,960  of  14,789.    Elapsed: 1:21:35.\n",
      "  Batch 13,000  of  14,789.    Elapsed: 1:21:50.\n",
      "  Batch 13,040  of  14,789.    Elapsed: 1:22:06.\n",
      "  Batch 13,080  of  14,789.    Elapsed: 1:22:21.\n",
      "  Batch 13,120  of  14,789.    Elapsed: 1:22:36.\n",
      "  Batch 13,160  of  14,789.    Elapsed: 1:22:51.\n",
      "  Batch 13,200  of  14,789.    Elapsed: 1:23:06.\n",
      "  Batch 13,240  of  14,789.    Elapsed: 1:23:21.\n",
      "  Batch 13,280  of  14,789.    Elapsed: 1:23:36.\n",
      "  Batch 13,320  of  14,789.    Elapsed: 1:23:51.\n",
      "  Batch 13,360  of  14,789.    Elapsed: 1:24:06.\n",
      "  Batch 13,400  of  14,789.    Elapsed: 1:24:21.\n",
      "  Batch 13,440  of  14,789.    Elapsed: 1:24:36.\n",
      "  Batch 13,480  of  14,789.    Elapsed: 1:24:51.\n",
      "  Batch 13,520  of  14,789.    Elapsed: 1:25:06.\n",
      "  Batch 13,560  of  14,789.    Elapsed: 1:25:22.\n",
      "  Batch 13,600  of  14,789.    Elapsed: 1:25:37.\n",
      "  Batch 13,640  of  14,789.    Elapsed: 1:25:52.\n",
      "  Batch 13,680  of  14,789.    Elapsed: 1:26:07.\n",
      "  Batch 13,720  of  14,789.    Elapsed: 1:26:22.\n",
      "  Batch 13,760  of  14,789.    Elapsed: 1:26:37.\n",
      "  Batch 13,800  of  14,789.    Elapsed: 1:26:52.\n",
      "  Batch 13,840  of  14,789.    Elapsed: 1:27:07.\n",
      "  Batch 13,880  of  14,789.    Elapsed: 1:27:22.\n",
      "  Batch 13,920  of  14,789.    Elapsed: 1:27:37.\n",
      "  Batch 13,960  of  14,789.    Elapsed: 1:27:52.\n",
      "  Batch 14,000  of  14,789.    Elapsed: 1:28:07.\n",
      "  Batch 14,040  of  14,789.    Elapsed: 1:28:24.\n",
      "  Batch 14,080  of  14,789.    Elapsed: 1:28:39.\n",
      "  Batch 14,120  of  14,789.    Elapsed: 1:28:54.\n",
      "  Batch 14,160  of  14,789.    Elapsed: 1:29:09.\n",
      "  Batch 14,200  of  14,789.    Elapsed: 1:29:24.\n",
      "  Batch 14,240  of  14,789.    Elapsed: 1:29:39.\n",
      "  Batch 14,280  of  14,789.    Elapsed: 1:29:55.\n",
      "  Batch 14,320  of  14,789.    Elapsed: 1:30:10.\n",
      "  Batch 14,360  of  14,789.    Elapsed: 1:30:25.\n",
      "  Batch 14,400  of  14,789.    Elapsed: 1:30:40.\n",
      "  Batch 14,440  of  14,789.    Elapsed: 1:30:55.\n",
      "  Batch 14,480  of  14,789.    Elapsed: 1:31:10.\n",
      "  Batch 14,520  of  14,789.    Elapsed: 1:31:25.\n",
      "  Batch 14,560  of  14,789.    Elapsed: 1:31:40.\n",
      "  Batch 14,600  of  14,789.    Elapsed: 1:31:55.\n",
      "  Batch 14,640  of  14,789.    Elapsed: 1:32:10.\n",
      "  Batch 14,680  of  14,789.    Elapsed: 1:32:25.\n",
      "  Batch 14,720  of  14,789.    Elapsed: 1:32:41.\n",
      "  Batch 14,760  of  14,789.    Elapsed: 1:32:56.\n",
      "\n",
      "  Average training loss: 0.05\n",
      "  Training epcoh took: 1:33:06\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.98\n",
      "  Validation Loss: 0.08\n",
      "  Validation took: 0:03:12\n",
      "\n",
      "======== Epoch 4 / 4 ========\n",
      "Training...\n",
      "  Batch    40  of  14,789.    Elapsed: 0:00:15.\n",
      "  Batch    80  of  14,789.    Elapsed: 0:00:30.\n",
      "  Batch   120  of  14,789.    Elapsed: 0:00:45.\n",
      "  Batch   160  of  14,789.    Elapsed: 0:01:00.\n",
      "  Batch   200  of  14,789.    Elapsed: 0:01:15.\n",
      "  Batch   240  of  14,789.    Elapsed: 0:01:30.\n",
      "  Batch   280  of  14,789.    Elapsed: 0:01:46.\n",
      "  Batch   320  of  14,789.    Elapsed: 0:02:01.\n",
      "  Batch   360  of  14,789.    Elapsed: 0:02:16.\n",
      "  Batch   400  of  14,789.    Elapsed: 0:02:31.\n",
      "  Batch   440  of  14,789.    Elapsed: 0:02:46.\n",
      "  Batch   480  of  14,789.    Elapsed: 0:03:01.\n",
      "  Batch   520  of  14,789.    Elapsed: 0:03:16.\n",
      "  Batch   560  of  14,789.    Elapsed: 0:03:31.\n",
      "  Batch   600  of  14,789.    Elapsed: 0:03:46.\n",
      "  Batch   640  of  14,789.    Elapsed: 0:04:01.\n",
      "  Batch   680  of  14,789.    Elapsed: 0:04:16.\n",
      "  Batch   720  of  14,789.    Elapsed: 0:04:31.\n",
      "  Batch   760  of  14,789.    Elapsed: 0:04:46.\n",
      "  Batch   800  of  14,789.    Elapsed: 0:05:01.\n",
      "  Batch   840  of  14,789.    Elapsed: 0:05:16.\n",
      "  Batch   880  of  14,789.    Elapsed: 0:05:31.\n",
      "  Batch   920  of  14,789.    Elapsed: 0:05:47.\n",
      "  Batch   960  of  14,789.    Elapsed: 0:06:02.\n",
      "  Batch 1,000  of  14,789.    Elapsed: 0:06:17.\n",
      "  Batch 1,040  of  14,789.    Elapsed: 0:06:32.\n",
      "  Batch 1,080  of  14,789.    Elapsed: 0:06:47.\n",
      "  Batch 1,120  of  14,789.    Elapsed: 0:07:02.\n",
      "  Batch 1,160  of  14,789.    Elapsed: 0:07:17.\n",
      "  Batch 1,200  of  14,789.    Elapsed: 0:07:32.\n",
      "  Batch 1,240  of  14,789.    Elapsed: 0:07:47.\n",
      "  Batch 1,280  of  14,789.    Elapsed: 0:08:02.\n",
      "  Batch 1,320  of  14,789.    Elapsed: 0:08:17.\n",
      "  Batch 1,360  of  14,789.    Elapsed: 0:08:32.\n",
      "  Batch 1,400  of  14,789.    Elapsed: 0:08:47.\n",
      "  Batch 1,440  of  14,789.    Elapsed: 0:09:03.\n",
      "  Batch 1,480  of  14,789.    Elapsed: 0:09:18.\n",
      "  Batch 1,520  of  14,789.    Elapsed: 0:09:33.\n",
      "  Batch 1,560  of  14,789.    Elapsed: 0:09:48.\n",
      "  Batch 1,600  of  14,789.    Elapsed: 0:10:03.\n",
      "  Batch 1,640  of  14,789.    Elapsed: 0:10:18.\n",
      "  Batch 1,680  of  14,789.    Elapsed: 0:10:33.\n",
      "  Batch 1,720  of  14,789.    Elapsed: 0:10:48.\n",
      "  Batch 1,760  of  14,789.    Elapsed: 0:11:03.\n",
      "  Batch 1,800  of  14,789.    Elapsed: 0:11:18.\n",
      "  Batch 1,840  of  14,789.    Elapsed: 0:11:33.\n",
      "  Batch 1,880  of  14,789.    Elapsed: 0:11:48.\n",
      "  Batch 1,920  of  14,789.    Elapsed: 0:12:03.\n",
      "  Batch 1,960  of  14,789.    Elapsed: 0:12:18.\n",
      "  Batch 2,000  of  14,789.    Elapsed: 0:12:34.\n",
      "  Batch 2,040  of  14,789.    Elapsed: 0:12:50.\n",
      "  Batch 2,080  of  14,789.    Elapsed: 0:13:05.\n",
      "  Batch 2,120  of  14,789.    Elapsed: 0:13:20.\n",
      "  Batch 2,160  of  14,789.    Elapsed: 0:13:35.\n",
      "  Batch 2,200  of  14,789.    Elapsed: 0:13:50.\n",
      "  Batch 2,240  of  14,789.    Elapsed: 0:14:05.\n",
      "  Batch 2,280  of  14,789.    Elapsed: 0:14:21.\n",
      "  Batch 2,320  of  14,789.    Elapsed: 0:14:36.\n",
      "  Batch 2,360  of  14,789.    Elapsed: 0:14:51.\n",
      "  Batch 2,400  of  14,789.    Elapsed: 0:15:06.\n",
      "  Batch 2,440  of  14,789.    Elapsed: 0:15:21.\n",
      "  Batch 2,480  of  14,789.    Elapsed: 0:15:36.\n",
      "  Batch 2,520  of  14,789.    Elapsed: 0:15:51.\n",
      "  Batch 2,560  of  14,789.    Elapsed: 0:16:06.\n",
      "  Batch 2,600  of  14,789.    Elapsed: 0:16:21.\n",
      "  Batch 2,640  of  14,789.    Elapsed: 0:16:36.\n",
      "  Batch 2,680  of  14,789.    Elapsed: 0:16:51.\n",
      "  Batch 2,720  of  14,789.    Elapsed: 0:17:07.\n",
      "  Batch 2,760  of  14,789.    Elapsed: 0:17:22.\n",
      "  Batch 2,800  of  14,789.    Elapsed: 0:17:37.\n",
      "  Batch 2,840  of  14,789.    Elapsed: 0:17:52.\n",
      "  Batch 2,880  of  14,789.    Elapsed: 0:18:07.\n",
      "  Batch 2,920  of  14,789.    Elapsed: 0:18:22.\n",
      "  Batch 2,960  of  14,789.    Elapsed: 0:18:37.\n",
      "  Batch 3,000  of  14,789.    Elapsed: 0:18:52.\n",
      "  Batch 3,040  of  14,789.    Elapsed: 0:19:07.\n",
      "  Batch 3,080  of  14,789.    Elapsed: 0:19:22.\n",
      "  Batch 3,120  of  14,789.    Elapsed: 0:19:37.\n",
      "  Batch 3,160  of  14,789.    Elapsed: 0:19:52.\n",
      "  Batch 3,200  of  14,789.    Elapsed: 0:20:07.\n",
      "  Batch 3,240  of  14,789.    Elapsed: 0:20:22.\n",
      "  Batch 3,280  of  14,789.    Elapsed: 0:20:38.\n",
      "  Batch 3,320  of  14,789.    Elapsed: 0:20:53.\n",
      "  Batch 3,360  of  14,789.    Elapsed: 0:21:08.\n",
      "  Batch 3,400  of  14,789.    Elapsed: 0:21:23.\n",
      "  Batch 3,440  of  14,789.    Elapsed: 0:21:38.\n",
      "  Batch 3,480  of  14,789.    Elapsed: 0:21:53.\n",
      "  Batch 3,520  of  14,789.    Elapsed: 0:22:08.\n",
      "  Batch 3,560  of  14,789.    Elapsed: 0:22:23.\n",
      "  Batch 3,600  of  14,789.    Elapsed: 0:22:38.\n",
      "  Batch 3,640  of  14,789.    Elapsed: 0:22:53.\n",
      "  Batch 3,680  of  14,789.    Elapsed: 0:23:08.\n",
      "  Batch 3,720  of  14,789.    Elapsed: 0:23:23.\n",
      "  Batch 3,760  of  14,789.    Elapsed: 0:23:38.\n",
      "  Batch 3,800  of  14,789.    Elapsed: 0:23:53.\n",
      "  Batch 3,840  of  14,789.    Elapsed: 0:24:08.\n",
      "  Batch 3,880  of  14,789.    Elapsed: 0:24:24.\n",
      "  Batch 3,920  of  14,789.    Elapsed: 0:24:39.\n",
      "  Batch 3,960  of  14,789.    Elapsed: 0:24:54.\n",
      "  Batch 4,000  of  14,789.    Elapsed: 0:25:09.\n",
      "  Batch 4,040  of  14,789.    Elapsed: 0:25:25.\n",
      "  Batch 4,080  of  14,789.    Elapsed: 0:25:41.\n",
      "  Batch 4,120  of  14,789.    Elapsed: 0:25:56.\n",
      "  Batch 4,160  of  14,789.    Elapsed: 0:26:11.\n",
      "  Batch 4,200  of  14,789.    Elapsed: 0:26:26.\n",
      "  Batch 4,240  of  14,789.    Elapsed: 0:26:41.\n",
      "  Batch 4,280  of  14,789.    Elapsed: 0:26:56.\n",
      "  Batch 4,320  of  14,789.    Elapsed: 0:27:11.\n",
      "  Batch 4,360  of  14,789.    Elapsed: 0:27:26.\n",
      "  Batch 4,400  of  14,789.    Elapsed: 0:27:41.\n",
      "  Batch 4,440  of  14,789.    Elapsed: 0:27:56.\n",
      "  Batch 4,480  of  14,789.    Elapsed: 0:28:11.\n",
      "  Batch 4,520  of  14,789.    Elapsed: 0:28:26.\n",
      "  Batch 4,560  of  14,789.    Elapsed: 0:28:42.\n",
      "  Batch 4,600  of  14,789.    Elapsed: 0:28:57.\n",
      "  Batch 4,640  of  14,789.    Elapsed: 0:29:12.\n",
      "  Batch 4,680  of  14,789.    Elapsed: 0:29:27.\n",
      "  Batch 4,720  of  14,789.    Elapsed: 0:29:42.\n",
      "  Batch 4,760  of  14,789.    Elapsed: 0:29:57.\n",
      "  Batch 4,800  of  14,789.    Elapsed: 0:30:12.\n",
      "  Batch 4,840  of  14,789.    Elapsed: 0:30:27.\n",
      "  Batch 4,880  of  14,789.    Elapsed: 0:30:42.\n",
      "  Batch 4,920  of  14,789.    Elapsed: 0:30:57.\n",
      "  Batch 4,960  of  14,789.    Elapsed: 0:31:12.\n",
      "  Batch 5,000  of  14,789.    Elapsed: 0:31:27.\n",
      "  Batch 5,040  of  14,789.    Elapsed: 0:31:42.\n",
      "  Batch 5,080  of  14,789.    Elapsed: 0:31:57.\n",
      "  Batch 5,120  of  14,789.    Elapsed: 0:32:12.\n",
      "  Batch 5,160  of  14,789.    Elapsed: 0:32:27.\n",
      "  Batch 5,200  of  14,789.    Elapsed: 0:32:42.\n",
      "  Batch 5,240  of  14,789.    Elapsed: 0:32:57.\n",
      "  Batch 5,280  of  14,789.    Elapsed: 0:33:12.\n",
      "  Batch 5,320  of  14,789.    Elapsed: 0:33:27.\n",
      "  Batch 5,360  of  14,789.    Elapsed: 0:33:42.\n",
      "  Batch 5,400  of  14,789.    Elapsed: 0:33:57.\n",
      "  Batch 5,440  of  14,789.    Elapsed: 0:34:12.\n",
      "  Batch 5,480  of  14,789.    Elapsed: 0:34:27.\n",
      "  Batch 5,520  of  14,789.    Elapsed: 0:34:42.\n",
      "  Batch 5,560  of  14,789.    Elapsed: 0:34:57.\n",
      "  Batch 5,600  of  14,789.    Elapsed: 0:35:12.\n",
      "  Batch 5,640  of  14,789.    Elapsed: 0:35:27.\n",
      "  Batch 5,680  of  14,789.    Elapsed: 0:35:42.\n",
      "  Batch 5,720  of  14,789.    Elapsed: 0:35:57.\n",
      "  Batch 5,760  of  14,789.    Elapsed: 0:36:12.\n",
      "  Batch 5,800  of  14,789.    Elapsed: 0:36:27.\n",
      "  Batch 5,840  of  14,789.    Elapsed: 0:36:42.\n",
      "  Batch 5,880  of  14,789.    Elapsed: 0:36:57.\n",
      "  Batch 5,920  of  14,789.    Elapsed: 0:37:12.\n",
      "  Batch 5,960  of  14,789.    Elapsed: 0:37:27.\n",
      "  Batch 6,000  of  14,789.    Elapsed: 0:37:42.\n",
      "  Batch 6,040  of  14,789.    Elapsed: 0:37:59.\n",
      "  Batch 6,080  of  14,789.    Elapsed: 0:38:14.\n",
      "  Batch 6,120  of  14,789.    Elapsed: 0:38:29.\n",
      "  Batch 6,160  of  14,789.    Elapsed: 0:38:44.\n",
      "  Batch 6,200  of  14,789.    Elapsed: 0:38:59.\n",
      "  Batch 6,240  of  14,789.    Elapsed: 0:39:14.\n",
      "  Batch 6,280  of  14,789.    Elapsed: 0:39:29.\n",
      "  Batch 6,320  of  14,789.    Elapsed: 0:39:44.\n",
      "  Batch 6,360  of  14,789.    Elapsed: 0:39:59.\n",
      "  Batch 6,400  of  14,789.    Elapsed: 0:40:14.\n",
      "  Batch 6,440  of  14,789.    Elapsed: 0:40:29.\n",
      "  Batch 6,480  of  14,789.    Elapsed: 0:40:44.\n",
      "  Batch 6,520  of  14,789.    Elapsed: 0:40:59.\n",
      "  Batch 6,560  of  14,789.    Elapsed: 0:41:14.\n",
      "  Batch 6,600  of  14,789.    Elapsed: 0:41:29.\n",
      "  Batch 6,640  of  14,789.    Elapsed: 0:41:44.\n",
      "  Batch 6,680  of  14,789.    Elapsed: 0:41:59.\n",
      "  Batch 6,720  of  14,789.    Elapsed: 0:42:14.\n",
      "  Batch 6,760  of  14,789.    Elapsed: 0:42:30.\n",
      "  Batch 6,800  of  14,789.    Elapsed: 0:42:45.\n",
      "  Batch 6,840  of  14,789.    Elapsed: 0:43:00.\n",
      "  Batch 6,880  of  14,789.    Elapsed: 0:43:15.\n",
      "  Batch 6,920  of  14,789.    Elapsed: 0:43:30.\n",
      "  Batch 6,960  of  14,789.    Elapsed: 0:43:45.\n",
      "  Batch 7,000  of  14,789.    Elapsed: 0:44:00.\n",
      "  Batch 7,040  of  14,789.    Elapsed: 0:44:15.\n",
      "  Batch 7,080  of  14,789.    Elapsed: 0:44:30.\n",
      "  Batch 7,120  of  14,789.    Elapsed: 0:44:45.\n",
      "  Batch 7,160  of  14,789.    Elapsed: 0:45:00.\n",
      "  Batch 7,200  of  14,789.    Elapsed: 0:45:15.\n",
      "  Batch 7,240  of  14,789.    Elapsed: 0:45:30.\n",
      "  Batch 7,280  of  14,789.    Elapsed: 0:45:45.\n",
      "  Batch 7,320  of  14,789.    Elapsed: 0:46:00.\n",
      "  Batch 7,360  of  14,789.    Elapsed: 0:46:15.\n",
      "  Batch 7,400  of  14,789.    Elapsed: 0:46:30.\n",
      "  Batch 7,440  of  14,789.    Elapsed: 0:46:45.\n",
      "  Batch 7,480  of  14,789.    Elapsed: 0:47:00.\n",
      "  Batch 7,520  of  14,789.    Elapsed: 0:47:15.\n",
      "  Batch 7,560  of  14,789.    Elapsed: 0:47:30.\n",
      "  Batch 7,600  of  14,789.    Elapsed: 0:47:45.\n",
      "  Batch 7,640  of  14,789.    Elapsed: 0:48:00.\n",
      "  Batch 7,680  of  14,789.    Elapsed: 0:48:15.\n",
      "  Batch 7,720  of  14,789.    Elapsed: 0:48:30.\n",
      "  Batch 7,760  of  14,789.    Elapsed: 0:48:45.\n",
      "  Batch 7,800  of  14,789.    Elapsed: 0:49:00.\n",
      "  Batch 7,840  of  14,789.    Elapsed: 0:49:15.\n",
      "  Batch 7,880  of  14,789.    Elapsed: 0:49:30.\n",
      "  Batch 7,920  of  14,789.    Elapsed: 0:49:45.\n",
      "  Batch 7,960  of  14,789.    Elapsed: 0:50:00.\n",
      "  Batch 8,000  of  14,789.    Elapsed: 0:50:15.\n",
      "  Batch 8,040  of  14,789.    Elapsed: 0:50:32.\n",
      "  Batch 8,080  of  14,789.    Elapsed: 0:50:47.\n",
      "  Batch 8,120  of  14,789.    Elapsed: 0:51:02.\n",
      "  Batch 8,160  of  14,789.    Elapsed: 0:51:17.\n",
      "  Batch 8,200  of  14,789.    Elapsed: 0:51:32.\n",
      "  Batch 8,240  of  14,789.    Elapsed: 0:51:47.\n",
      "  Batch 8,280  of  14,789.    Elapsed: 0:52:02.\n",
      "  Batch 8,320  of  14,789.    Elapsed: 0:52:17.\n",
      "  Batch 8,360  of  14,789.    Elapsed: 0:52:32.\n",
      "  Batch 8,400  of  14,789.    Elapsed: 0:52:47.\n",
      "  Batch 8,440  of  14,789.    Elapsed: 0:53:02.\n",
      "  Batch 8,480  of  14,789.    Elapsed: 0:53:17.\n",
      "  Batch 8,520  of  14,789.    Elapsed: 0:53:32.\n",
      "  Batch 8,560  of  14,789.    Elapsed: 0:53:47.\n",
      "  Batch 8,600  of  14,789.    Elapsed: 0:54:02.\n",
      "  Batch 8,640  of  14,789.    Elapsed: 0:54:17.\n",
      "  Batch 8,680  of  14,789.    Elapsed: 0:54:32.\n",
      "  Batch 8,720  of  14,789.    Elapsed: 0:54:47.\n",
      "  Batch 8,760  of  14,789.    Elapsed: 0:55:02.\n",
      "  Batch 8,800  of  14,789.    Elapsed: 0:55:17.\n",
      "  Batch 8,840  of  14,789.    Elapsed: 0:55:32.\n",
      "  Batch 8,880  of  14,789.    Elapsed: 0:55:47.\n",
      "  Batch 8,920  of  14,789.    Elapsed: 0:56:02.\n",
      "  Batch 8,960  of  14,789.    Elapsed: 0:56:17.\n",
      "  Batch 9,000  of  14,789.    Elapsed: 0:56:32.\n",
      "  Batch 9,040  of  14,789.    Elapsed: 0:56:47.\n",
      "  Batch 9,080  of  14,789.    Elapsed: 0:57:02.\n",
      "  Batch 9,120  of  14,789.    Elapsed: 0:57:17.\n",
      "  Batch 9,160  of  14,789.    Elapsed: 0:57:32.\n",
      "  Batch 9,200  of  14,789.    Elapsed: 0:57:47.\n",
      "  Batch 9,240  of  14,789.    Elapsed: 0:58:02.\n",
      "  Batch 9,280  of  14,789.    Elapsed: 0:58:17.\n",
      "  Batch 9,320  of  14,789.    Elapsed: 0:58:32.\n",
      "  Batch 9,360  of  14,789.    Elapsed: 0:58:47.\n",
      "  Batch 9,400  of  14,789.    Elapsed: 0:59:02.\n",
      "  Batch 9,440  of  14,789.    Elapsed: 0:59:17.\n",
      "  Batch 9,480  of  14,789.    Elapsed: 0:59:32.\n",
      "  Batch 9,520  of  14,789.    Elapsed: 0:59:47.\n",
      "  Batch 9,560  of  14,789.    Elapsed: 1:00:02.\n",
      "  Batch 9,600  of  14,789.    Elapsed: 1:00:17.\n",
      "  Batch 9,640  of  14,789.    Elapsed: 1:00:32.\n",
      "  Batch 9,680  of  14,789.    Elapsed: 1:00:47.\n",
      "  Batch 9,720  of  14,789.    Elapsed: 1:01:02.\n",
      "  Batch 9,760  of  14,789.    Elapsed: 1:01:17.\n",
      "  Batch 9,800  of  14,789.    Elapsed: 1:01:32.\n",
      "  Batch 9,840  of  14,789.    Elapsed: 1:01:47.\n",
      "  Batch 9,880  of  14,789.    Elapsed: 1:02:02.\n",
      "  Batch 9,920  of  14,789.    Elapsed: 1:02:17.\n",
      "  Batch 9,960  of  14,789.    Elapsed: 1:02:32.\n",
      "  Batch 10,000  of  14,789.    Elapsed: 1:02:47.\n",
      "  Batch 10,040  of  14,789.    Elapsed: 1:03:04.\n",
      "  Batch 10,080  of  14,789.    Elapsed: 1:03:19.\n",
      "  Batch 10,120  of  14,789.    Elapsed: 1:03:34.\n",
      "  Batch 10,160  of  14,789.    Elapsed: 1:03:49.\n",
      "  Batch 10,200  of  14,789.    Elapsed: 1:04:04.\n",
      "  Batch 10,240  of  14,789.    Elapsed: 1:04:19.\n",
      "  Batch 10,280  of  14,789.    Elapsed: 1:04:34.\n",
      "  Batch 10,320  of  14,789.    Elapsed: 1:04:49.\n",
      "  Batch 10,360  of  14,789.    Elapsed: 1:05:04.\n",
      "  Batch 10,400  of  14,789.    Elapsed: 1:05:19.\n",
      "  Batch 10,440  of  14,789.    Elapsed: 1:05:34.\n",
      "  Batch 10,480  of  14,789.    Elapsed: 1:05:49.\n",
      "  Batch 10,520  of  14,789.    Elapsed: 1:06:04.\n",
      "  Batch 10,560  of  14,789.    Elapsed: 1:06:19.\n",
      "  Batch 10,600  of  14,789.    Elapsed: 1:06:34.\n",
      "  Batch 10,640  of  14,789.    Elapsed: 1:06:49.\n",
      "  Batch 10,680  of  14,789.    Elapsed: 1:07:04.\n",
      "  Batch 10,720  of  14,789.    Elapsed: 1:07:19.\n",
      "  Batch 10,760  of  14,789.    Elapsed: 1:07:34.\n",
      "  Batch 10,800  of  14,789.    Elapsed: 1:07:49.\n",
      "  Batch 10,840  of  14,789.    Elapsed: 1:08:04.\n",
      "  Batch 10,880  of  14,789.    Elapsed: 1:08:19.\n",
      "  Batch 10,920  of  14,789.    Elapsed: 1:08:34.\n",
      "  Batch 10,960  of  14,789.    Elapsed: 1:08:49.\n",
      "  Batch 11,000  of  14,789.    Elapsed: 1:09:04.\n",
      "  Batch 11,040  of  14,789.    Elapsed: 1:09:19.\n",
      "  Batch 11,080  of  14,789.    Elapsed: 1:09:34.\n",
      "  Batch 11,120  of  14,789.    Elapsed: 1:09:49.\n",
      "  Batch 11,160  of  14,789.    Elapsed: 1:10:04.\n",
      "  Batch 11,200  of  14,789.    Elapsed: 1:10:19.\n",
      "  Batch 11,240  of  14,789.    Elapsed: 1:10:34.\n",
      "  Batch 11,280  of  14,789.    Elapsed: 1:10:49.\n",
      "  Batch 11,320  of  14,789.    Elapsed: 1:11:04.\n",
      "  Batch 11,360  of  14,789.    Elapsed: 1:11:19.\n",
      "  Batch 11,400  of  14,789.    Elapsed: 1:11:34.\n",
      "  Batch 11,440  of  14,789.    Elapsed: 1:11:49.\n",
      "  Batch 11,480  of  14,789.    Elapsed: 1:12:04.\n",
      "  Batch 11,520  of  14,789.    Elapsed: 1:12:19.\n",
      "  Batch 11,560  of  14,789.    Elapsed: 1:12:34.\n",
      "  Batch 11,600  of  14,789.    Elapsed: 1:12:49.\n",
      "  Batch 11,640  of  14,789.    Elapsed: 1:13:04.\n",
      "  Batch 11,680  of  14,789.    Elapsed: 1:13:19.\n",
      "  Batch 11,720  of  14,789.    Elapsed: 1:13:34.\n",
      "  Batch 11,760  of  14,789.    Elapsed: 1:13:49.\n",
      "  Batch 11,800  of  14,789.    Elapsed: 1:14:04.\n",
      "  Batch 11,840  of  14,789.    Elapsed: 1:14:19.\n",
      "  Batch 11,880  of  14,789.    Elapsed: 1:14:34.\n",
      "  Batch 11,920  of  14,789.    Elapsed: 1:14:49.\n",
      "  Batch 11,960  of  14,789.    Elapsed: 1:15:04.\n",
      "  Batch 12,000  of  14,789.    Elapsed: 1:15:19.\n",
      "  Batch 12,040  of  14,789.    Elapsed: 1:15:36.\n",
      "  Batch 12,080  of  14,789.    Elapsed: 1:15:51.\n",
      "  Batch 12,120  of  14,789.    Elapsed: 1:16:06.\n",
      "  Batch 12,160  of  14,789.    Elapsed: 1:16:21.\n",
      "  Batch 12,200  of  14,789.    Elapsed: 1:16:36.\n",
      "  Batch 12,240  of  14,789.    Elapsed: 1:16:51.\n",
      "  Batch 12,280  of  14,789.    Elapsed: 1:17:06.\n",
      "  Batch 12,320  of  14,789.    Elapsed: 1:17:21.\n",
      "  Batch 12,360  of  14,789.    Elapsed: 1:17:36.\n",
      "  Batch 12,400  of  14,789.    Elapsed: 1:17:51.\n",
      "  Batch 12,440  of  14,789.    Elapsed: 1:18:06.\n",
      "  Batch 12,480  of  14,789.    Elapsed: 1:18:21.\n",
      "  Batch 12,520  of  14,789.    Elapsed: 1:18:36.\n",
      "  Batch 12,560  of  14,789.    Elapsed: 1:18:51.\n",
      "  Batch 12,600  of  14,789.    Elapsed: 1:19:06.\n",
      "  Batch 12,640  of  14,789.    Elapsed: 1:19:21.\n",
      "  Batch 12,680  of  14,789.    Elapsed: 1:19:36.\n",
      "  Batch 12,720  of  14,789.    Elapsed: 1:19:51.\n",
      "  Batch 12,760  of  14,789.    Elapsed: 1:20:06.\n",
      "  Batch 12,800  of  14,789.    Elapsed: 1:20:21.\n",
      "  Batch 12,840  of  14,789.    Elapsed: 1:20:36.\n",
      "  Batch 12,880  of  14,789.    Elapsed: 1:20:51.\n",
      "  Batch 12,920  of  14,789.    Elapsed: 1:21:06.\n",
      "  Batch 12,960  of  14,789.    Elapsed: 1:21:21.\n",
      "  Batch 13,000  of  14,789.    Elapsed: 1:21:36.\n",
      "  Batch 13,040  of  14,789.    Elapsed: 1:21:51.\n",
      "  Batch 13,080  of  14,789.    Elapsed: 1:22:06.\n",
      "  Batch 13,120  of  14,789.    Elapsed: 1:22:21.\n",
      "  Batch 13,160  of  14,789.    Elapsed: 1:22:36.\n",
      "  Batch 13,200  of  14,789.    Elapsed: 1:22:51.\n",
      "  Batch 13,240  of  14,789.    Elapsed: 1:23:06.\n",
      "  Batch 13,280  of  14,789.    Elapsed: 1:23:21.\n",
      "  Batch 13,320  of  14,789.    Elapsed: 1:23:36.\n",
      "  Batch 13,360  of  14,789.    Elapsed: 1:23:51.\n",
      "  Batch 13,400  of  14,789.    Elapsed: 1:24:06.\n",
      "  Batch 13,440  of  14,789.    Elapsed: 1:24:21.\n",
      "  Batch 13,480  of  14,789.    Elapsed: 1:24:36.\n",
      "  Batch 13,520  of  14,789.    Elapsed: 1:24:51.\n",
      "  Batch 13,560  of  14,789.    Elapsed: 1:25:06.\n",
      "  Batch 13,600  of  14,789.    Elapsed: 1:25:21.\n",
      "  Batch 13,640  of  14,789.    Elapsed: 1:25:36.\n",
      "  Batch 13,680  of  14,789.    Elapsed: 1:25:51.\n",
      "  Batch 13,720  of  14,789.    Elapsed: 1:26:06.\n",
      "  Batch 13,760  of  14,789.    Elapsed: 1:26:21.\n",
      "  Batch 13,800  of  14,789.    Elapsed: 1:26:36.\n",
      "  Batch 13,840  of  14,789.    Elapsed: 1:26:51.\n",
      "  Batch 13,880  of  14,789.    Elapsed: 1:27:06.\n",
      "  Batch 13,920  of  14,789.    Elapsed: 1:27:21.\n",
      "  Batch 13,960  of  14,789.    Elapsed: 1:27:36.\n",
      "  Batch 14,000  of  14,789.    Elapsed: 1:27:51.\n",
      "  Batch 14,040  of  14,789.    Elapsed: 1:28:08.\n",
      "  Batch 14,080  of  14,789.    Elapsed: 1:28:23.\n",
      "  Batch 14,120  of  14,789.    Elapsed: 1:28:38.\n",
      "  Batch 14,160  of  14,789.    Elapsed: 1:28:53.\n",
      "  Batch 14,200  of  14,789.    Elapsed: 1:29:08.\n",
      "  Batch 14,240  of  14,789.    Elapsed: 1:29:23.\n",
      "  Batch 14,280  of  14,789.    Elapsed: 1:29:38.\n",
      "  Batch 14,320  of  14,789.    Elapsed: 1:29:53.\n",
      "  Batch 14,360  of  14,789.    Elapsed: 1:30:08.\n",
      "  Batch 14,400  of  14,789.    Elapsed: 1:30:23.\n",
      "  Batch 14,440  of  14,789.    Elapsed: 1:30:38.\n",
      "  Batch 14,480  of  14,789.    Elapsed: 1:30:53.\n",
      "  Batch 14,520  of  14,789.    Elapsed: 1:31:08.\n",
      "  Batch 14,560  of  14,789.    Elapsed: 1:31:23.\n",
      "  Batch 14,600  of  14,789.    Elapsed: 1:31:38.\n",
      "  Batch 14,640  of  14,789.    Elapsed: 1:31:53.\n",
      "  Batch 14,680  of  14,789.    Elapsed: 1:32:08.\n",
      "  Batch 14,720  of  14,789.    Elapsed: 1:32:23.\n",
      "  Batch 14,760  of  14,789.    Elapsed: 1:32:38.\n",
      "\n",
      "  Average training loss: 0.03\n",
      "  Training epcoh took: 1:32:49\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.98\n",
      "  Validation Loss: 0.09\n",
      "  Validation took: 0:03:12\n",
      "\n",
      "Training complete!\n",
      "Total training took 6:25:05 (h:mm:ss)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "seed_val = 22\n",
    "epochs = 4\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "train_loss_list = []\n",
    "dev_acc_list = []\n",
    "PATH = '/content/drive/My Drive/data'\n",
    "iter = 0 \n",
    "training_stats = []\n",
    "\n",
    "# Measure the total training time for the whole run.\n",
    "total_t0 = time.time()\n",
    "\n",
    "# For each epoch...\n",
    "for epoch_i in range(0, epochs):\n",
    "    \n",
    "\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')\n",
    "\n",
    "    t0 = time.time()\n",
    "    total_train_loss = 0\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "\n",
    "        # Progress update every 40 batches.\n",
    "        if step % 40 == 0 and not step == 0:\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            \n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "\n",
    "        if step % 2000 == 0 and not step == 0:\n",
    "            torch.save(model, \"/content/drive/My Drive/results/model_saved_\" + str(epoch_i) + \"_\"+ str(step) + \".pt\")\n",
    "            \n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "\n",
    "        model.zero_grad()       \n",
    "\n",
    "        outputs = model(b_input_ids, \n",
    "                    token_type_ids=None, \n",
    "                    attention_mask=b_input_mask, \n",
    "                    labels=b_labels)\n",
    "        loss = outputs[0]\n",
    "\n",
    "        total_train_loss += loss.item()\n",
    "        # Perform a backward pass to calculate the gradients.\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "    # Calculate the average loss over the training data.\n",
    "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
    "    \n",
    "    # Store the loss value for plotting the learning curve.\n",
    "    train_loss_list.append(avg_train_loss)\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n",
    "\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Running Validation...\")\n",
    "\n",
    "    t0 = time.time()\n",
    "    model.eval()\n",
    "\n",
    "    # Tracking variables \n",
    "    total_eval_accuracy = 0\n",
    "    total_eval_loss = 0\n",
    "    nb_eval_steps = 0\n",
    "\n",
    "    # Evaluate data for one epoch\n",
    "    for batch in validation_dataloader:\n",
    "        \n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "\n",
    "        with torch.no_grad():        \n",
    "            (loss, logits) = model(b_input_ids, \n",
    "                                   token_type_ids=None, \n",
    "                                   attention_mask=b_input_mask,\n",
    "                                   labels=b_labels)\n",
    "        total_eval_loss += loss.item()\n",
    "\n",
    "        # Move logits and labels to CPU\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
    "\n",
    "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
    "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
    "\n",
    "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
    "\n",
    "    validation_time = format_time(time.time() - t0)\n",
    "    \n",
    "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
    "    print(\"  Validation took: {:}\".format(validation_time))\n",
    "\n",
    "    # Record all statistics from this epoch.\n",
    "    training_stats.append(\n",
    "        {\n",
    "            'epoch': epoch_i + 1,\n",
    "            'Training Loss': avg_train_loss,\n",
    "            'Valid. Loss': avg_val_loss,+\n",
    "            'Valid. Accur.': avg_val_accuracy,\n",
    "            'Validation Time': validation_time\n",
    "        }\n",
    "    )\n",
    "\n",
    "print(\"\")\n",
    "print(\"Training complete!\")\n",
    "\n",
    "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "wvKseRSgrGO3",
    "outputId": "6e5cd275-f6a6-4015-fcb5-c0b09cf5d78e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaForSequenceClassification(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (classifier): RobertaClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "EpQynq9ieNBD",
    "outputId": "a9df9a51-77cf-40e9-fe54-07b93450e00a"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic": {
       "type": "string"
      },
      "text/plain": [
       "'/content/drive/My Drive/results'"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"/content/drive/My Drive/results\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tECNvmv3YPIJ"
   },
   "outputs": [],
   "source": [
    "torch.save(model,\"/content/drive/My Drive/results/roberta_final.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aHYf5NLDhVYu"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Food_Reviews_BERT.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "07b24e917df6498586fd161c68f77072": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4e1990521961423ab3065a568556d343",
      "placeholder": "​",
      "style": "IPY_MODEL_bb1e545aff1d4046b48c19d22205f952",
      "value": " 501M/501M [00:06&lt;00:00, 80.8MB/s]"
     }
    },
    "0abff727c8474082a391526fe3e5398a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5fafe301182a4e53863f88d2d8c17965",
      "max": 456318,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4eb582dc791b4324ba919c932409a3ce",
      "value": 456318
     }
    },
    "0d794f34fd764c49ae6c191571f16170": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "15698980e87846609ab193ebfe1ef349": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_cffec5b9ee254bb19846ecd80ff4cb22",
       "IPY_MODEL_07b24e917df6498586fd161c68f77072"
      ],
      "layout": "IPY_MODEL_4c22c969cf054857b1f743571148e7bc"
     }
    },
    "24352e494a794a17a0d3a40c65a9f348": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c6aed81e509843fa9ee6e9bb8e6220c7",
      "placeholder": "​",
      "style": "IPY_MODEL_50e27af94a474c8c94ac6ff0edfe7afc",
      "value": " 481/481 [00:27&lt;00:00, 17.8B/s]"
     }
    },
    "3223227416434d278cdeaf0b201f0546": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "4b126a7b755c418984a3890fbd0726b0": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4c22c969cf054857b1f743571148e7bc": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4e1990521961423ab3065a568556d343": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4eb582dc791b4324ba919c932409a3ce": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "50e27af94a474c8c94ac6ff0edfe7afc": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "566aed6c7c9747eebf3f20a438c6d60d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5fafe301182a4e53863f88d2d8c17965": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6cf378a35fa54fcfbabc73d95b39cfe0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "703a44b858ca4ad2a09590d09f1c0415": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7485244de9e341f28b0cc7e00c32ac7e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e8e95befa64f456e8c4cb97a3cf29305",
      "max": 898823,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d70562775d9f444b870d52f744a2ddac",
      "value": 898823
     }
    },
    "8a1712076b494f849fff037a6a2e67e6": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "91a552bae06e432bb7b48c330eb258f7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_703a44b858ca4ad2a09590d09f1c0415",
      "placeholder": "​",
      "style": "IPY_MODEL_ad89dadf9ef048479a313f640ae62b52",
      "value": " 899k/899k [00:12&lt;00:00, 71.6kB/s]"
     }
    },
    "ac463a6bbe7146cb9237db3264a3eebe": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ad89dadf9ef048479a313f640ae62b52": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "bb1e545aff1d4046b48c19d22205f952": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c076bc5728994168b6263d91768d8d6c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0abff727c8474082a391526fe3e5398a",
       "IPY_MODEL_d264cf5ee28d4dbcb8eb0d8a614e007e"
      ],
      "layout": "IPY_MODEL_cc17fdd219cd43049944a6d8c72fb2a7"
     }
    },
    "c6aed81e509843fa9ee6e9bb8e6220c7": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cc17fdd219cd43049944a6d8c72fb2a7": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cc4cdf98053a4f06a9ea2056f35a3d29": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4b126a7b755c418984a3890fbd0726b0",
      "max": 481,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3223227416434d278cdeaf0b201f0546",
      "value": 481
     }
    },
    "cd71e1f5340c4c06bf25a238b93a3304": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7485244de9e341f28b0cc7e00c32ac7e",
       "IPY_MODEL_91a552bae06e432bb7b48c330eb258f7"
      ],
      "layout": "IPY_MODEL_db78ceb0e26d467c8f0144698b8344c3"
     }
    },
    "cffec5b9ee254bb19846ecd80ff4cb22": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8a1712076b494f849fff037a6a2e67e6",
      "max": 501200538,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6cf378a35fa54fcfbabc73d95b39cfe0",
      "value": 501200538
     }
    },
    "d264cf5ee28d4dbcb8eb0d8a614e007e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0d794f34fd764c49ae6c191571f16170",
      "placeholder": "​",
      "style": "IPY_MODEL_ac463a6bbe7146cb9237db3264a3eebe",
      "value": " 456k/456k [00:00&lt;00:00, 475kB/s]"
     }
    },
    "d70562775d9f444b870d52f744a2ddac": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "db78ceb0e26d467c8f0144698b8344c3": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e8e95befa64f456e8c4cb97a3cf29305": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ed4b291d5a414a6ab92333b57e666c2c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_cc4cdf98053a4f06a9ea2056f35a3d29",
       "IPY_MODEL_24352e494a794a17a0d3a40c65a9f348"
      ],
      "layout": "IPY_MODEL_566aed6c7c9747eebf3f20a438c6d60d"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
